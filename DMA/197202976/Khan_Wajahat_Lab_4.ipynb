{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1xxMXNDF7ckw"
   },
   "source": [
    "## DMA 2023 ##\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`, as well as your name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "5sdHHukr6mmS"
   },
   "outputs": [],
   "source": [
    "NAME = \"Wajahat Khan\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oyb_RNpFreOr"
   },
   "source": [
    "# Lab 4: Neural Networks #\n",
    "**Please read the following instructions very carefully**\n",
    "\n",
    "## Working on the assignment / FAQs\n",
    "- **Always use the seed/random_state as *42* wherever applicable** (This is to ensure repeatability in answers, across questions, students and coding environments).\n",
    "- All questions will be graded manually.\n",
    "- Most questions have two cells:\n",
    "  - A code cell for your work/code\n",
    "  - A text cell for giving your final answer\n",
    "- The points each question carries are indicated.\n",
    "- Most assignments have bonus questions for extra credit, do try them out!\n",
    "- **Submitting the assignment** : Download the '.ipynb' and '.pdf' files from Colab and upload them to Gradescope. Do not delete any outputs from cells before submitting. Make sure to assign pages to questions when uploading your PDF to Gradescope.\n",
    "- That's about it. Happy coding!\n",
    "\n",
    "\n",
    "## About the dataset\n",
    "This assignment uses a dataset obtained from the JSE Data Archive that contains biological and self-reported activity traits of a sample of college students at a single university uploaded in 2013. Background Information on the dataset: http://jse.amstat.org/v21n2/froelich/eyecolorgender.txt\n",
    "\n",
    "For this lab, the dataset has already been split into a training set `df_train` and a test set `df_test`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "yj9Uh79ereOs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "n6SRFrhfreOt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget http://askoski.berkeley.edu/~zp/lab_4_training.csv\n",
    "!wget http://askoski.berkeley.edu/~zp/lab_4_test.csv\n",
    "\n",
    "df_train = pd.read_csv('./lab_4_training.csv')\n",
    "df_test = pd.read_csv('./lab_4_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGt_10ZAreOv"
   },
   "source": [
    "***\n",
    "### Question 1 (1 point)\n",
    "Calculate a baseline accuracy measure using the majority class, assuming a target variable of `gender`. The majority class is the most common value of the target variable in a particular dataset. Accuracy is calculated as (true positives + true negatives) / (all negatives and positives)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZPiLgekreOw"
   },
   "source": [
    "**Question 1.a**  \n",
    "Find the majority class in the training set. If you always predicted this class in the training set, what would your accuracy be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "iYjEFc1greOx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female majority training set\n",
      "0.5427852348993288\n",
      "0.5427852348993288\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "which_gender = df_train[\"gender\"].value_counts().idxmax()\n",
    "#print(df_train[\"gender\"].value_counts())\n",
    "Accuracy_caculation = (df_train['gender'] == which_gender).mean()\n",
    "\n",
    "#This class method\"\n",
    "gender_counts =  df_train['gender'].value_counts()\n",
    "accuracy_2 = gender_counts[\"female\"] / len(df_train)\n",
    "print(which_gender + \" majority training set\")\n",
    "print(Accuracy_caculation)\n",
    "print(accuracy_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5w2LK2QxUFKv"
   },
   "source": [
    "**Answer: 0.5427852348993288**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULPKW0IvreOy"
   },
   "source": [
    "**Question 1.b**   \n",
    "If you always predicted this same class (majority from the training set) in the test set, what would your accuracy be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "dfU5mwh405vq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female majority training set\n",
      "0.5226130653266332\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "which_gender = df_test[\"gender\"].value_counts().idxmax()\n",
    "Accuracy_caculation = (df_test['gender'] == which_gender).mean()\n",
    "print(which_gender + \" majority training set\")\n",
    "print(Accuracy_caculation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pINRUJxG05v4"
   },
   "source": [
    "**Answer: 0.5226130653266332**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKb2Ju-GreO0"
   },
   "source": [
    "***\n",
    "### Question 2 (1.5 points)###\n",
    "Get started with Neural Networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYI6e3F3reO0"
   },
   "source": [
    "   \n",
    "Choose a NN implementation (we recommend Sklearn MLPclassifier) and specify which you choose. Be sure the implementation allows you to modify the number of hidden layers and hidden nodes per layer.  \n",
    "\n",
    "NOTE: When possible, specify the logsig (`sigmoid`/`logistic`) function as the transfer function (another word for activation function) and use Levenberg-Marquardt backpropagation (`lbfgs`). It is possible to specify logistic in Sklearn MLPclassifier.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WHCSftWa2bF"
   },
   "source": [
    "**My NN implementation of choice: YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4am3sGc4reO1"
   },
   "source": [
    "**Question 2.a**   \n",
    "Train a neural network with a single 10 node hidden layer. Only use the `height` feature of the dataset to predict the `gender`. You will have to change `gender` to a 0 and 1 class. After training, use your trained model to predict the class (`gender`) using the `height` feature from the training set. What is the accuracy of this prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8439597315436241"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## I am going to impor these files each time cause this dumb computer keeps turning gender into Nan values somehow\n",
    "## I checked my code like 10 times and still can't tell when I rerun the cell it does that.\n",
    "df_train = pd.read_csv('./lab_4_training.csv')\n",
    "df_test = pd.read_csv('./lab_4_test.csv')\n",
    "\n",
    "# YOUR CODE HERE\n",
    "## I assume we can assign either or for the male and female\n",
    "#df_train[\"gender\"] = df_train[\"gender\"].map({\"male\": 0, \"female\": 1})\n",
    "\n",
    "df_train_copy = df_train.copy()\n",
    "# Encode gender as 0 and 1 https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "# pretty cool, I don't have keep doing the map stuff, pretty cool\n",
    "\n",
    "le = LabelEncoder() \n",
    "df_train_copy['gender'] = le.fit_transform(df_train_copy['gender'])\n",
    "X_train = df_train_copy[['height']]\n",
    "y_train = df_train_copy['gender']\n",
    "\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(10,), activation='logistic', solver='lbfgs', random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_train_pred = clf.predict(X_train)\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "accuracy_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EuaCk0l0067q"
   },
   "source": [
    "**Answer: 0.8439597315436241**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkqzIeshreO2"
   },
   "source": [
    "**Question 2.b (0.5 points)**  \n",
    "Take the trained model from question 2.a and use it to predict the test set. This can be accomplished by taking the trained model and giving it the `height` feature values from the test set. What is the accuracy of this model on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "Tw25ezWp07hj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8542713567839196"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "## I am going to impor these files each time cause this dumb computer keeps turning gender into Nan values somehow\n",
    "## I checked my code like 10 times and still can't tell when I rerun the cell it does that.\n",
    "\n",
    "df_train = pd.read_csv('./lab_4_training.csv')\n",
    "df_test = pd.read_csv('./lab_4_test.csv')\n",
    "\n",
    "# YOUR CODE HERE\n",
    "## I assume we can assign either or for the male and female\n",
    "#df_test[\"gender\"] = df_test[\"gender\"].map({\"male\": 0, \"female\": 1})\n",
    "\n",
    "# Create a copy of the test dataframe\n",
    "df_test_copy = df_test.copy()\n",
    "df_test_copy['gender'] = le.transform(df_test_copy['gender'])\n",
    "\n",
    "X_test = df_test_copy[['height']]\n",
    "y_test = df_test_copy['gender']\n",
    "\n",
    "y_test_pred = clf.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "accuracy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HbHMAFvw07hm"
   },
   "source": [
    "**Answer: 0.8542713567839196 **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMmIfsNEreO3"
   },
   "source": [
    "**Question 2.c**   \n",
    "Neural Networks tend to prefer smaller, normalized feature values. Try taking the log of the `height` feature in both training and testing sets or use a Standard Scalar operation in SKlearn to centre and normalize the data between 0-1 for continuous values. Repeat question 2.a and 2.b with the log version or the normalized and centered version of this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "wDhCZPaU07_8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8439597315436241\n",
      "0.8542713567839196\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "## just having the copies instead of reimporting them might be better.\n",
    "df_train_normalized = df_train.copy()\n",
    "df_test_normalized = df_test.copy()\n",
    "\n",
    "# scaler, StandardScaler thingy mucghtyyy\n",
    "scaler = StandardScaler()\n",
    "df_train_normalized['height'] = scaler.fit_transform(df_train_normalized[['height']])\n",
    "df_test_normalized['height']  = scaler.transform(df_test_normalized[['height']])\n",
    "\n",
    "# using the same LabelEncoder as before, 0 or 1, it assigns by itself instead of me mapping\n",
    "df_train_normalized['gender'] = le.transform(df_train_normalized['gender'])\n",
    "df_test_normalized['gender'] = le.transform(df_test_normalized['gender'])\n",
    "\n",
    "# trainNormilized, height and Gender bruv --> Train\n",
    "X_train_normalized = df_train_normalized[['height']]\n",
    "y_train_normalized = df_train_normalized['gender']\n",
    "\n",
    "# testNormilized, height and Gender ---> Test\n",
    "X_test_normalized = df_test_normalized[['height']]\n",
    "y_test_normalized = df_test_normalized['gender']\n",
    "\n",
    "# Create and train the MLPClassifier with normalized height feature\n",
    "clf = MLPClassifier(hidden_layer_sizes=(10,),\n",
    "                               activation='logistic', max_iter = 200, verbose = 10, solver='lbfgs', random_state=42)\n",
    "clf.fit(X_train_normalized, y_train_normalized)\n",
    "\n",
    "## train, accruracyy\n",
    "y_train_pred_normalized   = clf.predict(X_train_normalized)\n",
    "accuracy_train_normalized = accuracy_score(y_train_normalized, y_train_pred_normalized)\n",
    "\n",
    "## test. accruacy\n",
    "y_test_pred_normalized   = clf.predict(X_test_normalized)\n",
    "accuracy_test_normalized = accuracy_score(y_test_normalized, y_test_pred_normalized)\n",
    "\n",
    "print(accuracy_train_normalized)\n",
    "print(accuracy_test_normalized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTO2KMti07__"
   },
   "source": [
    "**Answer (accuracy on training set): 0.8439597315436241**\n",
    "## Note I get a different answer with the same code on collab:  0.834731543624161"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ps1JmsR2uXiV"
   },
   "source": [
    "**Answer (accuracy on test set): 0.8542713567839196**\n",
    "## Note I get a different answer with the same code on collab:  0.831658291457286"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I would like to go with 0.8347 as it seems more correct if you take a log, the nubmers should of changed? Idk whats going on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_SlOdcarePC"
   },
   "source": [
    "***\n",
    "\n",
    "### Question 3 (1 point) ###\n",
    "Many of the remaining features in the dataset are categorical. No ML method accepts categorical features, so transform `year`, `eyecolor`, `exercise` into a set of binary features, one feature per unique original feature value, and mark the binary feature as ‘1’ if the feature value matches the original value and ‘0’ otherwise. Using only these one-hot transformed features, train and predict the class of the test set. What was your accuracy using a Neural Network with a single 10 node hidden layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5452261306532663"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "train_data = new_dftrain[['year', 'eyecolor', 'exercise']]\n",
    "test_data = new_dftest[['year', 'eyecolor', 'exercise']]\n",
    "encoded_train_data = pd.get_dummies(train_data, columns=[\"year\", \"eyecolor\", \"exercise\"])\n",
    "encoded_test_data = pd.get_dummies(test_data, columns=[\"year\", \"eyecolor\", \"exercise\"])\n",
    "\n",
    "X_train = encoded_train_data\n",
    "Y_train = new_dftrain['gender']\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(10,), activation='logistic',\n",
    "                    max_iter=200, solver='lbfgs', verbose=10, random_state=42)\n",
    "\n",
    "classifier.fit(X_train, Y_train)\n",
    "X_test = encoded_test_data\n",
    "Y_test = new_dftest['gender']\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyQ1EvAY1Ait"
   },
   "source": [
    "**Answer: 0.5452261306532663**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSSr9sBlrePG"
   },
   "source": [
    "***\n",
    "### Question 4 (3 points)###\n",
    "Using a NN, report the accuracy on the test set of a model that trained only on `height` and the `eyecolor` features of instances in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMNSlOmJrePG"
   },
   "source": [
    "**Question 4.a**  \n",
    "What is the accuracy on the test set using the original `height` values (no pre-processing) and `eyecolor` as a one-hot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8618090452261307"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./lab_4_training.csv')\n",
    "df_test = pd.read_csv('./lab_4_test.csv')\n",
    "\n",
    "X_train_height = df_train[['height']]\n",
    "X_test_height = df_test[['height']]\n",
    "\n",
    "X_train_eyecolor = pd.get_dummies(df_train['eyecolor'], prefix='eyecolor')\n",
    "X_test_eyecolor = pd.get_dummies(df_test['eyecolor'], prefix='eyecolor')\n",
    "\n",
    "\n",
    "X_train_combined = pd.concat([X_train_height, X_train_eyecolor], axis=1)\n",
    "X_test_combined = pd.concat([X_test_height, X_test_eyecolor], axis=1)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10,), activation='logistic', solver='lbfgs', random_state=42)\n",
    "mlp.fit(X_train_combined, df_train['gender'])\n",
    "y_pred = mlp.predict(X_test_combined)\n",
    "accuracy_test = accuracy_score(df_test['gender'], y_pred)\n",
    "accuracy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CaL2o0TW1Cks"
   },
   "source": [
    "**Answer: 0.8618090452261307**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NC8Ipx9QrePH"
   },
   "source": [
    "**Question 4.b**  \n",
    "What is the accuracy on the test set using the log of `height` values (applied to both training and testing sets) and `eyecolor` as a one-hot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8618090452261307"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./lab_4_training.csv')\n",
    "df_test = pd.read_csv('./lab_4_test.csv')\n",
    "\n",
    "\n",
    "X_train_eyecolor = pd.get_dummies(df_train['eyecolor'], prefix='eyecolor')\n",
    "X_test_eyecolor = pd.get_dummies(df_test['eyecolor'], prefix='eyecolor')\n",
    "X_train_height_log = np.log1p(df_train[['height']])\n",
    "X_test_height_log = np.log1p(df_test[['height']])\n",
    "\n",
    "X_train_combined_log = pd.concat([X_train_height_log, X_train_eyecolor], axis=1)\n",
    "X_test_combined_log = pd.concat([X_test_height_log, X_test_eyecolor], axis=1)\n",
    "\n",
    "mlp_log = MLPClassifier(hidden_layer_sizes=(10,), \n",
    "                        activation='logistic', solver='lbfgs', random_state=42)\n",
    "mlp_log.fit(X_train_combined_log, df_train['gender'])\n",
    "y_pred_log = mlp_log.predict(X_test_combined_log)\n",
    "accuracy_test_log = accuracy_score(df_test['gender'], y_pred_log)\n",
    "accuracy_test_log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pt3NMp1M1DG4"
   },
   "source": [
    "**Answer: 0.8618090452261307**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYm2jqnprePI"
   },
   "source": [
    "**Question 4.c**  \n",
    "What is the accuracy on the test set using the Z-score of `height` values and `eyecolor` as a one-hot?\n",
    "\n",
    "Z-score is a normalization function. It is the value of a feature minus the average value for that feature (in the training set), divided by the standard deviation of that feature (in the training set). Remember that, whenever applying a function to a feature in the training set, it also has to be applied to that same feature in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "P3mDjF6N1DoN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8668341708542714"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./lab_4_training.csv')\n",
    "df_test = pd.read_csv('./lab_4_test.csv')\n",
    "\n",
    "height_mean = df_train['height'].mean()\n",
    "height_std = df_train['height'].std()\n",
    "\n",
    "X_train_height_zscore = (df_train['height'] - height_mean) / height_std\n",
    "X_test_height_zscore = (df_test['height'] - height_mean) / height_std\n",
    "\n",
    "\n",
    "X_train_eyecolor = pd.get_dummies(df_train['eyecolor'], \n",
    "                                  prefix='eyecolor')\n",
    "X_test_eyecolor = pd.get_dummies(df_test['eyecolor'], \n",
    "                                 prefix='eyecolor')\n",
    "\n",
    "X_train_combined_zscore = pd.concat([X_train_height_zscore, \n",
    "                                     X_train_eyecolor], axis=1)\n",
    "\n",
    "X_test_combined_zscore = pd.concat([X_test_height_zscore, \n",
    "                                    X_test_eyecolor], axis=1)\n",
    "\n",
    "\n",
    "mlp_zscore = MLPClassifier(hidden_layer_sizes=(10,), \n",
    "                           activation='logistic', solver='lbfgs', random_state=42)\n",
    "\n",
    "mlp_zscore.fit(X_train_combined_zscore, df_train['gender'])\n",
    "y_pred_zscore = mlp_zscore.predict(X_test_combined_zscore)\n",
    "accuracy_test_zscore = accuracy_score(df_test['gender'], y_pred_zscore)\n",
    "accuracy_test_zscore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAnuY8Sv1DoO"
   },
   "source": [
    "**Answer: 0.8668341708542714**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fh9qwu_9rePJ"
   },
   "source": [
    "***\n",
    "### Question 5 (1.5 points) ###\n",
    "Repeat question 4 for `playgames` & `eyecolor`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "II5bc2lGAUDD"
   },
   "source": [
    "**Question 5.a**  \\\\\n",
    "What is the accuracy on the test set using the original `playgames` values (no pre-processing) and `eyecolor` as a one-hot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.678391959798995"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = new_dftrain[['playgames', 'eyecolor']]\n",
    "encoded_train_features = pd.get_dummies(train_features, columns=[\"eyecolor\"])\n",
    "test_features = new_dftest[['playgames', 'eyecolor']]\n",
    "encoded_test_features = pd.get_dummies(test_features, columns=[\"eyecolor\"])\n",
    "\n",
    "X_train_features = encoded_train_features\n",
    "Y_train_gender = new_dftrain['gender']\n",
    "\n",
    "classifier_5a = MLPClassifier(hidden_layer_sizes=(10,), activation='logistic',\n",
    "                    max_iter=200, solver='lbfgs', verbose=10, random_state=42)\n",
    "classifier_5a.fit(X_train_features, Y_train_gender)\n",
    "\n",
    "\n",
    "X_test_features = encoded_test_features\n",
    "Y_test_gender = new_dftest['gender']\n",
    "y_pred = classifier_5a.predict(X_test_features)\n",
    "accuracy = accuracy_score(Y_test_gender, y_pred)\n",
    "accuracy                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNqB2UTxAm9l"
   },
   "source": [
    "**Answer: 0.678391959798995**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EUk8EFdAeD1"
   },
   "source": [
    "**Question 5.b**  \\\\\n",
    "What is the accuracy on the test set using the log of `playgames` values (applied to both training and testing sets) and `eyecolor` as a one-hot?\n",
    "\n",
    "Note: You can drop rows that have 0 in the `playgames` column, in order to avoid -inf values when applying log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>year</th>\n",
       "      <th>eyecolor</th>\n",
       "      <th>height</th>\n",
       "      <th>miles</th>\n",
       "      <th>brothers</th>\n",
       "      <th>sisters</th>\n",
       "      <th>computertime</th>\n",
       "      <th>exercise</th>\n",
       "      <th>exercisehours</th>\n",
       "      <th>musiccds</th>\n",
       "      <th>playgames</th>\n",
       "      <th>watchtv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1303</td>\n",
       "      <td>male</td>\n",
       "      <td>20</td>\n",
       "      <td>second</td>\n",
       "      <td>green</td>\n",
       "      <td>73.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 gender  age    year eyecolor  height  miles  brothers  sisters  \\\n",
       "0        1303   male   20  second    green    73.0  210.0         0        1   \n",
       "\n",
       "   computertime exercise  exercisehours  musiccds  playgames  watchtv  \n",
       "0          10.0      Yes            5.0      50.0        1.0     15.0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train[df_train['playgames'] > 0]\n",
    "df_test = df_test[df_test['playgames'] > 0] ## --> this only selecting rows that have value greater than 0, which should be same thing?\n",
    "df_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6300813008130082"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Data\n",
    "\n",
    "train_features = new_dftrain[['playgames', 'eyecolor']]\n",
    "encoded_train_features = pd.get_dummies(train_features, columns=[\"eyecolor\"])\n",
    "encoded_train_features = encoded_train_features[encoded_train_features['playgames'] > 0]\n",
    "encoded_train_features['playgames'] = np.log(encoded_train_features['playgames'])\n",
    "\n",
    "\n",
    "test_features = new_dftest[['playgames', 'eyecolor']]\n",
    "encoded_test_features = pd.get_dummies(test_features, columns=[\"eyecolor\"])\n",
    "encoded_test_features = encoded_test_features[encoded_test_features['playgames'] > 0]\n",
    "encoded_test_features['playgames'] = np.log(encoded_test_features['playgames'])\n",
    "\n",
    "\n",
    "X_train_features = encoded_train_features\n",
    "Y_train_gender = new_dftrain[new_dftrain['playgames'] > 0]\n",
    "Y_train_gender = Y_train_gender['gender']\n",
    "\n",
    "\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(10,), activation='logistic',\n",
    "                    max_iter=200, solver='lbfgs', verbose=10, random_state=42)\n",
    "classifier.fit(X_train_features, Y_train_gender)\n",
    "\n",
    "\n",
    "X_test_features = encoded_test_features\n",
    "Y_test_gender = new_dftest[new_dftest['playgames'] > 0]\n",
    "Y_test_gender = Y_test_gender['gender']\n",
    "y_pred = classifier.predict(X_test_features)\n",
    "accuracy = accuracy_score(Y_test_gender, y_pred)\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2C9_xTUAnaU"
   },
   "source": [
    "**Answer: 0.6300813008130082**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqf-3iQ1Aebj"
   },
   "source": [
    "**Question 5.c** \\\\\n",
    "What is the accuracy on the test set using the Z-score of `playgames` values and `eyecolor` as a one-hot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "zSNSl76eAkKz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6757999999946341"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "df_train = pd.read_csv('./lab_4_training.csv')\n",
    "df_test = pd.read_csv('./lab_4_test.csv')\n",
    "df_train = df_train[df_train['playgames'] > 0]\n",
    "df_test = df_test[df_test['playgames'] > 0]\n",
    "\n",
    "\n",
    "X_train_eyecolor = pd.get_dummies(df_train['eyecolor'], prefix='eyecolor')\n",
    "X_test_eyecolor = pd.get_dummies(df_test['eyecolor'], prefix='eyecolor')\n",
    "playgames_mean = df_train['playgames'].mean()\n",
    "playgames_std = df_train['playgames'].std()\n",
    "X_train_playgames_zscore = (df_train['playgames'] - playgames_mean) / playgames_std\n",
    "X_test_playgames_zscore = (df_test['playgames'] - playgames_mean) / playgames_std\n",
    "X_train_combined_playgames_zscore = pd.concat([X_train_playgames_zscore, X_train_eyecolor], axis=1)\n",
    "X_test_combined_playgames_zscore = pd.concat([X_test_playgames_zscore, X_test_eyecolor], axis=1)\n",
    "mlp_playgames_zscore = MLPClassifier(hidden_layer_sizes=(10,), activation='logistic',\n",
    "                    max_iter=200, solver='lbfgs', verbose=10, random_state = 42)\n",
    "\n",
    "mlp_playgames_zscore.fit(X_train_combined_playgames_zscore, df_train['gender'])\n",
    "y_pred_playgames_zscore = mlp_playgames_zscore.predict(X_test_combined_playgames_zscore)\n",
    "accuracy_test_playgames_zscore = accuracy_score(df_test['gender'], y_pred_playgames_zscore) \n",
    "accuracy_test_playgames_zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlDfGvy61EMS"
   },
   "source": [
    "**Answer: 0.6757999999946341**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYVuaPWgrePL"
   },
   "source": [
    "***\n",
    "### Question 6 (2 points)###\n",
    "Combine the features from question 3, 4, and 5 (`year`, `eyecolor`, `exercise`, `height`, `playgames`). For numeric features use the best normalization method from questions 4 and 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1iAiFhlFrePM"
   },
   "source": [
    "**Question 6.a**   \n",
    "What was the NN accuracy on the test set using the single 10 node hidden layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "QuLJ6sTB1FfN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8189999999927642"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "df_train = pd.read_csv('./lab_4_training.csv')\n",
    "df_test = pd.read_csv('./lab_4_test.csv')\n",
    "df_train = df_train[df_train['playgames'] > 0]\n",
    "df_test = df_test[df_test['playgames'] > 0]\n",
    "\n",
    "\n",
    "height_mean = df_train['height'].mean()\n",
    "height_std = df_train['height'].std()\n",
    "X_train_height_zscore = (df_train['height'] - height_mean) / height_std\n",
    "X_test_height_zscore = (df_test['height'] - height_mean) / height_std\n",
    "\n",
    "\n",
    "playgames_mean = df_train['playgames'].mean()\n",
    "playgames_std = df_train['playgames'].std()\n",
    "X_train_playgames_zscore = (df_train['playgames'] - playgames_mean) / playgames_std\n",
    "X_test_playgames_zscore = (df_test['playgames'] - playgames_mean) / playgames_std\n",
    "categorical_features = ['year', 'eyecolor', 'exercise']\n",
    "X_train_categorical = pd.get_dummies(df_train[categorical_features], columns=categorical_features, prefix=categorical_features)\n",
    "X_test_categorical = pd.get_dummies(df_test[categorical_features], columns=categorical_features, prefix=categorical_features)\n",
    "X_train_combined = pd.concat([X_train_height_zscore, X_train_playgames_zscore, X_train_categorical], axis=1)\n",
    "X_test_combined = pd.concat([X_test_height_zscore, X_test_playgames_zscore, X_test_categorical], axis=1)\n",
    "\n",
    "mlp_combined = MLPClassifier(hidden_layer_sizes=(10,), activation='logistic', solver='lbfgs', random_state=42)\n",
    "mlp_combined.fit(X_train_combined, df_train['gender'])\n",
    "\n",
    "y_pred_combined = mlp_combined.predict(X_test_combined)\n",
    "accuracy_test_combined = accuracy_score(df_test['gender'], y_pred_combined)\n",
    "accuracy_test_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1foS74O01FfP"
   },
   "source": [
    "**Answer: 0.8189999999927642**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jusc-kofrePP"
   },
   "source": [
    "***\n",
    "### Question 7- Bonus (1 point)###\n",
    "Can you improve your test set prediction accuracy by 3% or more? See how close to that milestone of improvement you can get by modifying the hyperparameters of  Neural Networks (the number of hidden layers, number of hidden nodes in each layer, the learning rate, the type of activation function etc.).\n",
    "\n",
    "A great guide to tuning parameters is explained in this guide: http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf. While the guide is specific to SVM and in particular the C and gamma parameters of the RBF kernel, the method applies more generally to any ML technique with tuning parameters.\n",
    "\n",
    "Please give your new prediction accuracy on the test set, and write a paragraph in a text cell below with an explanation of your approach and evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2rFY8D4Q1GsZ"
   },
   "source": [
    "**Answer: YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WwQ1o2BZDtKM"
   },
   "source": [
    "**Explanation: YOUR ANSWER HERE**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "GTO2KMti07__",
    "YAnuY8Sv1DoO",
    "ZlDfGvy61EMS",
    "1foS74O01FfP",
    "2rFY8D4Q1GsZ"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
