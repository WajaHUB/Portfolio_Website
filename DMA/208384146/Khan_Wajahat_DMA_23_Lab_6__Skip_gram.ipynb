{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IDlU-kLCKDVZ"
   },
   "outputs": [],
   "source": [
    "NAME = \"Wajahat Khan\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kW9zL4V6KDVc"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ECD5r2hFKDVd",
    "nbgrader": {
     "checksum": "9a0ec075584699a44c46933457b0a8ba",
     "grade": false,
     "grade_id": "cell-a910b376742d04c0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Lab 6: Skip Gram\n",
    "\n",
    "**Please read the following instructions very carefully**\n",
    "\n",
    "## Working on the assignment / FAQs\n",
    "- **Always use the seed/random_state as *42* wherever applicable** (This is to ensure repeatability in answers, across students and coding environments)\n",
    "- The type of question and the points they carry are indicated in each question cell\n",
    "- To avoid any ambiguity, each question also specifies what *value* must be set. Note that these are dummy values and not the answers\n",
    "- If an autograded question has multiple answers (due to differences in handling NaNs, zeros etc.), all answers will be considered.\n",
    "- You can delete the `raise NotImplementedError()`\n",
    "- **Submitting the assignment** : Download the '.ipynb' file from Colab and upload it to bcourses. Do not delete any outputs from cells before submitting.\n",
    "- That's about it. Happy coding!\n",
    "\n",
    "\n",
    "Available software:\n",
    " - Python's Gensim module: https://radimrehurek.com/gensim/ (install using pip)\n",
    "\n",
    "_Note: The most important hyper parameters of skip-gram/CBOW are vector size and windows size_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "Vsocwry-KDVe",
    "nbgrader": {
     "checksum": "a09a0bf3042da711c4bf843e9b4a4189",
     "grade": false,
     "grade_id": "cell-bf780e597c0216c8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "outputId": "1d39d239-5ce4-4e1d-983b-a321c187dc11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\jackf\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\jackf\\anaconda3\\lib\\site-packages (from gensim) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\jackf\\anaconda3\\lib\\site-packages (from gensim) (1.11.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\jackf\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in c:\\users\\jackf\\anaconda3\\lib\\site-packages (from gensim) (2.0.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\jackf\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (2.0.3)\n",
      "Requirement already satisfied: pyfume in c:\\users\\jackf\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (0.2.25)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jackf\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jackf\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\jackf\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2023.3)\n",
      "Requirement already satisfied: simpful in c:\\users\\jackf\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.11.0)\n",
      "Requirement already satisfied: fst-pso in c:\\users\\jackf\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jackf\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Requirement already satisfied: miniful in c:\\users\\jackf\\anaconda3\\lib\\site-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TIcyAqlk6Qpy",
    "outputId": "5ebcf003-0346-486e-99be-c76397b05133"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "model = api.load('word2vec-google-news-300') # this step might take ~10-15 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ZF74G9bDKDVh",
    "nbgrader": {
     "checksum": "47031c66b74746d23ccc5e8369446a4b",
     "grade": false,
     "grade_id": "cell-3f89500615a0096f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### **Q1 (1 point)**\n",
    "Find the cosine similarity between the following word pairs\n",
    "\n",
    "- (France, England)\n",
    "- (come, go)\n",
    "- (England, London)\n",
    "- (France, Rocket)\n",
    "- (big, bigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "id": "SZD5ZaMvKDVk",
    "nbgrader": {
     "checksum": "4d52dda406c3d8cd5e37d29755f0fb12",
     "grade": false,
     "grade_id": "cell-fbbe575f8f5a6368",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#Replace 0 with the code / value; Do not delete this cell\n",
    "similarity_pair1 = model.similarity(\"France\", \"England\")\n",
    "similarity_pair2 = model.similarity(\"come\", \"go\")\n",
    "similarity_pair3 = model.similarity(\"England\", \"London\")\n",
    "similarity_pair4 = model.similarity(\"France\", \"Rocket\")\n",
    "similarity_pair5 = model.similarity(\"big\", \"bigger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "deletable": false,
    "editable": false,
    "id": "tFUPLSK7KDVp",
    "nbgrader": {
     "checksum": "569aa8b664a41d901bf7b0a5e23e9930",
     "grade": true,
     "grade_id": "cell-929d59ed5d67f618",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "outputId": "c32bf233-2ecd-480e-d834-7acdda825767"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39804947 0.6604678 0.4399286 0.071141735 0.68423855\n"
     ]
    }
   ],
   "source": [
    "#This is an autograded cell, do not edit/delete\n",
    "print(similarity_pair1, similarity_pair2, similarity_pair3, similarity_pair4, similarity_pair5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ZcqpWCjJKDVs",
    "nbgrader": {
     "checksum": "a7f270405ddf9ecbffde36e6c096b818",
     "grade": false,
     "grade_id": "cell-ccd6618b4fac3715",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### **Q2 (1 point)**\n",
    "Write an expression to extract the vector representations of the words:\n",
    "\n",
    "- France\n",
    "- England\n",
    "- smaller\n",
    "- bigger\n",
    "- rocket\n",
    "- big\n",
    "\n",
    "Get only the first 5 elements for each vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "ElgK5QLuGi6S"
   },
   "outputs": [],
   "source": [
    "#Replace 0 with the code / value to get the first 5 elements of each vector; Do not delete this cell\n",
    "vector_1 = model[\"France\"][:5]\n",
    "vector_2 = model[\"England\"][:5]\n",
    "vector_3 = model[\"smaller\"][:5]\n",
    "vector_4 = model[\"bigger\"][:5]\n",
    "vector_5 = model[\"rocket\"][:5]\n",
    "vector_6 = model[\"big\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Hkj2ROGTKDVv",
    "nbgrader": {
     "checksum": "401940f859774b3c1ec48338fa15682e",
     "grade": true,
     "grade_id": "cell-6f34229370fa873f",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04858398 0.07861328 0.32421875 0.03491211 0.07714844]\n",
      "[-0.19824219  0.11523438  0.0625     -0.05834961  0.2265625 ]\n",
      "[-0.05004883  0.03417969 -0.0703125   0.17578125  0.00689697]\n",
      "[-0.06542969 -0.09521484 -0.06225586  0.16210938  0.01989746]\n",
      "[-0.03198242  0.27148438 -0.2890625  -0.15429688  0.16894531]\n",
      "[ 0.11132812  0.10595703 -0.07373047  0.18847656  0.07666016]\n"
     ]
    }
   ],
   "source": [
    "#This is an autograded cell, do not edit/delete\n",
    "print(vector_1)\n",
    "print(vector_2)\n",
    "print(vector_3)\n",
    "print(vector_4)\n",
    "print(vector_5)\n",
    "print(vector_6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "2UBnMwiXKDVy",
    "nbgrader": {
     "checksum": "ac8b42811c924e7988f17b9dbd3f71ef",
     "grade": false,
     "grade_id": "cell-4ad44071d3785409",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### **Q3 (1 point)**\n",
    "Find the euclidean distances between the word pairs :\n",
    "\n",
    "- (France, England)\n",
    "- (smaller, bigger)\n",
    "- (England, London)\n",
    "- (France, Rocket)\n",
    "- (big, bigger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "JYUdXmCOMg45"
   },
   "outputs": [],
   "source": [
    "#Replace 0 with the code / value; Do not delete this cell\n",
    "\n",
    "from scipy.spatial import distance ## --> I got this from scikit learn \n",
    "# link: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.euclidean_distances.html\n",
    "\n",
    "eu_dist1 = distance.euclidean(model[\"France\"], model[\"England\"])\n",
    "eu_dist2 = distance.euclidean(model[\"smaller\"], model[\"bigger\"])\n",
    "eu_dist3 = distance.euclidean(model[\"England\"], model[\"London\"])\n",
    "eu_dist4 = distance.euclidean(model[\"France\"], model[\"Rocket\"])\n",
    "eu_dist5 = distance.euclidean(model[\"big\"], model[\"bigger\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "HsSg0l2UKDV6",
    "nbgrader": {
     "checksum": "17796eb5de342e8f8e841aa137a2c41c",
     "grade": true,
     "grade_id": "cell-15ffa50b82de21ad",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.015106678009033\n",
      "1.8618743419647217\n",
      "2.875283718109131\n",
      "3.892071008682251\n",
      "1.9586496353149414\n"
     ]
    }
   ],
   "source": [
    "#This is an autograded cell, do not edit / delete\n",
    "print(eu_dist1)\n",
    "print(eu_dist2)\n",
    "print(eu_dist3)\n",
    "print(eu_dist4)\n",
    "print(eu_dist5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "XvO2iU7QKDWA",
    "nbgrader": {
     "checksum": "afc0e843c7545e2df83448feda9f28f5",
     "grade": false,
     "grade_id": "cell-7cd8b9b67386376d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### **Q4 (1 point)**\n",
    "Time to dabble with the power of Word2Vec. Find the 2 closest words  for the following conditions:  \n",
    "- (King - Man + Queen)\n",
    "- (bigger - big + small)\n",
    "- (waiting - wait + run)\n",
    "- (Texas + Milwaukee – Wisconsin)\n",
    "\n",
    "Note: If your kernel crashes due to low memory and restarts, reload the model from the top and try running this part again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "deletable": false,
    "id": "jCxWmA1eKDWB",
    "nbgrader": {
     "checksum": "50ef096feb166865434fe2fca3d41f99",
     "grade": false,
     "grade_id": "cell-b72201968c5fd1ec",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#Replace 0 with the code / value; Do not delete this cell\n",
    "\n",
    "closest1 = model.most_similar(positive = ['King', 'Queen'], negative = ['Man'])[:2] \n",
    "closest2 = model.most_similar(positive = ['bigger', 'small'], negative = ['big'])[:2] \n",
    "closest3 = model.most_similar(positive = ['waiting', 'run'], negative = ['wait'])[:2] \n",
    "closest4 = model.most_similar(positive = ['Texas', 'Milwaukee'], negative = ['Wisconsin'])[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "io9elfD8KDWE",
    "nbgrader": {
     "checksum": "f9c5ff502264f29d2632c6387f92686a",
     "grade": true,
     "grade_id": "cell-b69718ab0e1470bc",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Queen_Elizabeth', 0.525791585445404), ('monarch', 0.5004087090492249)]\n",
      "[('larger', 0.7402471899986267), ('smaller', 0.7329993844032288)]\n",
      "[('running', 0.5654535889625549), ('runs', 0.49640005826950073)]\n",
      "[('Houston', 0.7767744660377502), ('Fort_Worth', 0.7270510792732239)]\n"
     ]
    }
   ],
   "source": [
    "#This is an autograded cell, do not edit/delete\n",
    "print(closest1)\n",
    "print(closest2)\n",
    "print(closest3)\n",
    "print(closest4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "erUu4u71KDWJ",
    "nbgrader": {
     "checksum": "6432058d78f4fa52224c48a3b3e71d0d",
     "grade": false,
     "grade_id": "cell-73dca0e2072fef91",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### **Q5 (3 points)**\n",
    "Using the vectors for the words in the Google News dataset, apply K-means clustering (K=2) and find the top 5 most representative words/phrases of each cluster.\n",
    "\n",
    "*Note: Since there are ~3Mil words in the vocabulary, you can downsample it to 25k randomly selected words*  \\\\\n",
    "*Hint: The \"similar_by_vector\" method might be useful*\n",
    "\n",
    "**Do not delete the below cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "iqTEPYr_YuRu"
   },
   "outputs": [],
   "source": [
    "# Replace 0 with the code / value; Do not delete this cell\n",
    "# YOUR CODE HERE\n",
    "from sklearn.cluster import KMeans\n",
    "from random import sample\n",
    "\n",
    "# https://radimrehurek.com/gensim/models/keyedvectors.html\n",
    "\n",
    "sampled_words = sample(model.index_to_key, 2500)\n",
    "kmeans = KMeans(n_clusters= 2, n_init=10, \n",
    "                random_state=42).fit([model[word] for word in sampled_words])\n",
    "\n",
    "most_rep_cluster1 = model.similar_by_vector(kmeans.cluster_centers_[0], topn=5)\n",
    "most_rep_cluster2 = model.similar_by_vector(kmeans.cluster_centers_[1], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "deletable": false,
    "id": "M3jN02fOKDWK",
    "nbgrader": {
     "checksum": "7ecef46689f11d4d0a6fed72e049235f",
     "grade": true,
     "grade_id": "cell-80b177848b8b0212",
     "locked": false,
     "points": 3,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Emil_Protalinski_Published', 0.9183648228645325), ('By_HuDie_####-##-##', 0.9160116314888), ('By_XiaoBing_####-##-##', 0.9148709177970886), ('By_QianMian_####-##-##', 0.9128484129905701), ('STACY_LEE', 0.9120089411735535)]\n",
      "[('http_dol##.net_index###.html_http', 0.9203289747238159), ('dol##.net_index####.html_http_dol##.net', 0.910273551940918), ('index###.html_http_dol##.net_index###.html', 0.9092676043510437), ('Deltagen_undertakes', 0.9084193110466003), ('By_TRICIA_SCRUGGS', 0.9058576226234436)]\n"
     ]
    }
   ],
   "source": [
    "#This is an autograded cell, do not edit/delete\n",
    "print(most_rep_cluster1)\n",
    "print(most_rep_cluster2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "rmdtLoHkKDWR",
    "nbgrader": {
     "checksum": "0467b27a0f59504cbb62b851a002386f",
     "grade": false,
     "grade_id": "cell-5b2a5e8ff6c74323",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### **Q6 (1 point)**\n",
    "What loss function does the skipgram model use and briefly describe what this function is minimizing.\n",
    "\n",
    "**Do not delete the below cell**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "SyOASYXOKDWS",
    "nbgrader": {
     "checksum": "774aef2c5bf8ef9d92e3489d1cd80390",
     "grade": true,
     "grade_id": "cell-90cc4b2c0ae8e2c2",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "\n",
    "**The skipgram model uses the funcation called negative sampling, which basically reduces the complexity of the training model, its like the softmax loss funcation in that way. The purpose of it is to train the word embeddings so they compare the relation between the words, like the simarily score for King and Queen we did above. THe model will increase if it doesn't classify correctly.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "dbpuJx9CKDWV",
    "nbgrader": {
     "checksum": "c14f6069f64cc86ab6e384d28df270d8",
     "grade": false,
     "grade_id": "cell-74a177caaabb5009",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### **Bonus Question (1 point)**\n",
    "Find at least 2 interesting word vec combinations like the ones given in Q4\n",
    "\n",
    "**Do not delete the below cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "deletable": false,
    "id": "pQM8C_T7KDWW",
    "nbgrader": {
     "checksum": "c2d42b5327f4b020c7e1706506dd5ce9",
     "grade": true,
     "grade_id": "cell-7351297993d72e83",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# \"Paris - France + Italy\"\n",
    "# \"Cricket - India + Pakistan\" ## was trying to the current world cup but it doesn't have the names\n",
    "\n",
    "closest1 = model.most_similar(positive = ['Paris', 'Italy'], negative = ['France'])[:2] \n",
    "closest2 = model.most_similar(positive = ['ODI', 'Pakistan'], negative = ['India'])[:2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "ULdYIXstC9ZD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Milan', 0.7222141623497009), ('Rome', 0.702830970287323)]\n",
      "[('Afridi', 0.6969332098960876), ('Inzamam', 0.6848824620246887)]\n"
     ]
    }
   ],
   "source": [
    "print(closest1)\n",
    "print(closest2)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
