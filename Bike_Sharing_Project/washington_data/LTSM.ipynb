{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81eacf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd5aafa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e470a0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>727</td>\n",
       "      <td>2012-12-27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>0.226642</td>\n",
       "      <td>0.652917</td>\n",
       "      <td>0.350133</td>\n",
       "      <td>247</td>\n",
       "      <td>1867</td>\n",
       "      <td>2114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>728</td>\n",
       "      <td>2012-12-28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.255046</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.155471</td>\n",
       "      <td>644</td>\n",
       "      <td>2451</td>\n",
       "      <td>3095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>729</td>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.242400</td>\n",
       "      <td>0.752917</td>\n",
       "      <td>0.124383</td>\n",
       "      <td>159</td>\n",
       "      <td>1182</td>\n",
       "      <td>1341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>730</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255833</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.350754</td>\n",
       "      <td>364</td>\n",
       "      <td>1432</td>\n",
       "      <td>1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>731</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.215833</td>\n",
       "      <td>0.223487</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.154846</td>\n",
       "      <td>439</td>\n",
       "      <td>2290</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>731 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "0          1  2011-01-01       1   0     1        0        6           0   \n",
       "1          2  2011-01-02       1   0     1        0        0           0   \n",
       "2          3  2011-01-03       1   0     1        0        1           1   \n",
       "3          4  2011-01-04       1   0     1        0        2           1   \n",
       "4          5  2011-01-05       1   0     1        0        3           1   \n",
       "..       ...         ...     ...  ..   ...      ...      ...         ...   \n",
       "726      727  2012-12-27       1   1    12        0        4           1   \n",
       "727      728  2012-12-28       1   1    12        0        5           1   \n",
       "728      729  2012-12-29       1   1    12        0        6           0   \n",
       "729      730  2012-12-30       1   1    12        0        0           0   \n",
       "730      731  2012-12-31       1   1    12        0        1           1   \n",
       "\n",
       "     weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
       "0             2  0.344167  0.363625  0.805833   0.160446     331         654   \n",
       "1             2  0.363478  0.353739  0.696087   0.248539     131         670   \n",
       "2             1  0.196364  0.189405  0.437273   0.248309     120        1229   \n",
       "3             1  0.200000  0.212122  0.590435   0.160296     108        1454   \n",
       "4             1  0.226957  0.229270  0.436957   0.186900      82        1518   \n",
       "..          ...       ...       ...       ...        ...     ...         ...   \n",
       "726           2  0.254167  0.226642  0.652917   0.350133     247        1867   \n",
       "727           2  0.253333  0.255046  0.590000   0.155471     644        2451   \n",
       "728           2  0.253333  0.242400  0.752917   0.124383     159        1182   \n",
       "729           1  0.255833  0.231700  0.483333   0.350754     364        1432   \n",
       "730           2  0.215833  0.223487  0.577500   0.154846     439        2290   \n",
       "\n",
       "      cnt  \n",
       "0     985  \n",
       "1     801  \n",
       "2    1349  \n",
       "3    1562  \n",
       "4    1600  \n",
       "..    ...  \n",
       "726  2114  \n",
       "727  3095  \n",
       "728  1341  \n",
       "729  1796  \n",
       "730  2729  \n",
       "\n",
       "[731 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = r'C:\\Users\\jackf\\OneDrive\\Desktop\\Bike_Sharing\\UCI_Bike_Sharing\\data\\day.csv'\n",
    "day_Bike = pd.read_csv(file_path)\n",
    "day_Bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c37a2240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jackf\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jackf\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jackf\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From C:\\Users\\jackf\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "19/19 [==============================] - 5s 52ms/step - loss: 24461810.0000 - val_loss: 22307888.0000\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 24438038.0000 - val_loss: 22273864.0000\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 24386688.0000 - val_loss: 22206518.0000\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 24294130.0000 - val_loss: 22096634.0000\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 24154948.0000 - val_loss: 21944074.0000\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 23974494.0000 - val_loss: 21758054.0000\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 23763792.0000 - val_loss: 21551338.0000\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 23535832.0000 - val_loss: 21334938.0000\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 23301758.0000 - val_loss: 21115616.0000\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 23067882.0000 - val_loss: 20897472.0000\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 22837616.0000 - val_loss: 20684564.0000\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 22612138.0000 - val_loss: 20477588.0000\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 22392992.0000 - val_loss: 20278350.0000\n",
      "Epoch 14/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 22184390.0000 - val_loss: 20083368.0000\n",
      "Epoch 15/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 21978338.0000 - val_loss: 19896988.0000\n",
      "Epoch 16/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 21781584.0000 - val_loss: 19714446.0000\n",
      "Epoch 17/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 21589380.0000 - val_loss: 19540178.0000\n",
      "Epoch 18/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 21405592.0000 - val_loss: 19368528.0000\n",
      "Epoch 19/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 21223924.0000 - val_loss: 19201514.0000\n",
      "Epoch 20/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 21047478.0000 - val_loss: 19040638.0000\n",
      "Epoch 21/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 20876842.0000 - val_loss: 18884014.0000\n",
      "Epoch 22/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 20710576.0000 - val_loss: 18728458.0000\n",
      "Epoch 23/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 20546392.0000 - val_loss: 18580150.0000\n",
      "Epoch 24/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 20388520.0000 - val_loss: 18432770.0000\n",
      "Epoch 25/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 20232142.0000 - val_loss: 18290202.0000\n",
      "Epoch 26/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 20081174.0000 - val_loss: 18150288.0000\n",
      "Epoch 27/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 19932004.0000 - val_loss: 18012988.0000\n",
      "Epoch 28/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 19785634.0000 - val_loss: 17878786.0000\n",
      "Epoch 29/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 19641260.0000 - val_loss: 17745400.0000\n",
      "Epoch 30/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 19499786.0000 - val_loss: 17613966.0000\n",
      "Epoch 31/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 19359558.0000 - val_loss: 17485592.0000\n",
      "Epoch 32/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 19222064.0000 - val_loss: 17358394.0000\n",
      "Epoch 33/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 19086272.0000 - val_loss: 17234274.0000\n",
      "Epoch 34/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 18952952.0000 - val_loss: 17110966.0000\n",
      "Epoch 35/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 18821050.0000 - val_loss: 16989354.0000\n",
      "Epoch 36/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 18690994.0000 - val_loss: 16870028.0000\n",
      "Epoch 37/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 18563212.0000 - val_loss: 16751607.0000\n",
      "Epoch 38/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 18436458.0000 - val_loss: 16635193.0000\n",
      "Epoch 39/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 18311506.0000 - val_loss: 16518417.0000\n",
      "Epoch 40/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 18187702.0000 - val_loss: 16406068.0000\n",
      "Epoch 41/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 18065890.0000 - val_loss: 16294095.0000\n",
      "Epoch 42/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 17945818.0000 - val_loss: 16182538.0000\n",
      "Epoch 43/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 17826050.0000 - val_loss: 16072443.0000\n",
      "Epoch 44/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 17707060.0000 - val_loss: 15963751.0000\n",
      "Epoch 45/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 17589842.0000 - val_loss: 15854197.0000\n",
      "Epoch 46/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 17472816.0000 - val_loss: 15748364.0000\n",
      "Epoch 47/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 17358408.0000 - val_loss: 15642826.0000\n",
      "Epoch 48/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 17244190.0000 - val_loss: 15538573.0000\n",
      "Epoch 49/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 17131902.0000 - val_loss: 15434846.0000\n",
      "Epoch 50/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 17020464.0000 - val_loss: 15331654.0000\n",
      "Epoch 51/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 16908926.0000 - val_loss: 15229781.0000\n",
      "Epoch 52/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 16798998.0000 - val_loss: 15128614.0000\n",
      "Epoch 53/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 16689426.0000 - val_loss: 15028285.0000\n",
      "Epoch 54/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 16582237.0000 - val_loss: 14928677.0000\n",
      "Epoch 55/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 16474073.0000 - val_loss: 14831083.0000\n",
      "Epoch 56/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 16368326.0000 - val_loss: 14734590.0000\n",
      "Epoch 57/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 16264103.0000 - val_loss: 14637594.0000\n",
      "Epoch 58/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 16160396.0000 - val_loss: 14542599.0000\n",
      "Epoch 59/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 16056715.0000 - val_loss: 14449958.0000\n",
      "Epoch 60/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 15955630.0000 - val_loss: 14356153.0000\n",
      "Epoch 61/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 15855060.0000 - val_loss: 14263481.0000\n",
      "Epoch 62/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 15754524.0000 - val_loss: 14171911.0000\n",
      "Epoch 63/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 15654738.0000 - val_loss: 14080111.0000\n",
      "Epoch 64/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 31ms/step - loss: 15555547.0000 - val_loss: 13989866.0000\n",
      "Epoch 65/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 15457410.0000 - val_loss: 13899658.0000\n",
      "Epoch 66/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 15360016.0000 - val_loss: 13811261.0000\n",
      "Epoch 67/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 15264209.0000 - val_loss: 13724046.0000\n",
      "Epoch 68/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 15168735.0000 - val_loss: 13636599.0000\n",
      "Epoch 69/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 15073959.0000 - val_loss: 13549077.0000\n",
      "Epoch 70/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 14978914.0000 - val_loss: 13464203.0000\n",
      "Epoch 71/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 14886267.0000 - val_loss: 13377466.0000\n",
      "Epoch 72/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 14792604.0000 - val_loss: 13291646.0000\n",
      "Epoch 73/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 14699537.0000 - val_loss: 13208406.0000\n",
      "Epoch 74/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 14608082.0000 - val_loss: 13125424.0000\n",
      "Epoch 75/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 14517672.0000 - val_loss: 13042516.0000\n",
      "Epoch 76/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 14427120.0000 - val_loss: 12960760.0000\n",
      "Epoch 77/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 14337140.0000 - val_loss: 12879564.0000\n",
      "Epoch 78/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 14248574.0000 - val_loss: 12797432.0000\n",
      "Epoch 79/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 14159571.0000 - val_loss: 12717576.0000\n",
      "Epoch 80/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 14072125.0000 - val_loss: 12636842.0000\n",
      "Epoch 81/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 13984287.0000 - val_loss: 12556250.0000\n",
      "Epoch 82/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 13896846.0000 - val_loss: 12477410.0000\n",
      "Epoch 83/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 13811305.0000 - val_loss: 12400048.0000\n",
      "Epoch 84/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 13726004.0000 - val_loss: 12322651.0000\n",
      "Epoch 85/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 13641392.0000 - val_loss: 12245275.0000\n",
      "Epoch 86/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 13556249.0000 - val_loss: 12168667.0000\n",
      "Epoch 87/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 13472132.0000 - val_loss: 12092087.0000\n",
      "Epoch 88/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 13388786.0000 - val_loss: 12017250.0000\n",
      "Epoch 89/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 13305772.0000 - val_loss: 11942033.0000\n",
      "Epoch 90/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 13223265.0000 - val_loss: 11865901.0000\n",
      "Epoch 91/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 13140463.0000 - val_loss: 11792445.0000\n",
      "Epoch 92/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 13060313.0000 - val_loss: 11718754.0000\n",
      "Epoch 93/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 12978635.0000 - val_loss: 11645358.0000\n",
      "Epoch 94/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 12898626.0000 - val_loss: 11573697.0000\n",
      "Epoch 95/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 12819897.0000 - val_loss: 11501892.0000\n",
      "Epoch 96/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 12740384.0000 - val_loss: 11430925.0000\n",
      "Epoch 97/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 12661724.0000 - val_loss: 11359201.0000\n",
      "Epoch 98/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 12583264.0000 - val_loss: 11287248.0000\n",
      "Epoch 99/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 12504807.0000 - val_loss: 11218563.0000\n",
      "Epoch 100/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 12429425.0000 - val_loss: 11150197.0000\n",
      "Epoch 101/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 12353321.0000 - val_loss: 11082655.0000\n",
      "Epoch 102/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 12278068.0000 - val_loss: 11013987.0000\n",
      "Epoch 103/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 12202122.0000 - val_loss: 10945487.0000\n",
      "Epoch 104/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 12126916.0000 - val_loss: 10876690.0000\n",
      "Epoch 105/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 12051398.0000 - val_loss: 10809329.0000\n",
      "Epoch 106/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 11977330.0000 - val_loss: 10741600.0000\n",
      "Epoch 107/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 11902349.0000 - val_loss: 10675715.0000\n",
      "Epoch 108/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 11828939.0000 - val_loss: 10609549.0000\n",
      "Epoch 109/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 11754972.0000 - val_loss: 10543324.0000\n",
      "Epoch 110/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 11683004.0000 - val_loss: 10478456.0000\n",
      "Epoch 111/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 11611706.0000 - val_loss: 10414001.0000\n",
      "Epoch 112/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 11539375.0000 - val_loss: 10350585.0000\n",
      "Epoch 113/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 11469429.0000 - val_loss: 10286746.0000\n",
      "Epoch 114/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 11398540.0000 - val_loss: 10223127.0000\n",
      "Epoch 115/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 11327935.0000 - val_loss: 10160492.0000\n",
      "Epoch 116/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 11258719.0000 - val_loss: 10099506.0000\n",
      "Epoch 117/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 11190012.0000 - val_loss: 10037282.0000\n",
      "Epoch 118/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 11121077.0000 - val_loss: 9975623.0000\n",
      "Epoch 119/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 11053027.0000 - val_loss: 9914367.0000\n",
      "Epoch 120/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 10984409.0000 - val_loss: 9855185.0000\n",
      "Epoch 121/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 10918351.0000 - val_loss: 9794978.0000\n",
      "Epoch 122/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 10851708.0000 - val_loss: 9734875.0000\n",
      "Epoch 123/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 10784509.0000 - val_loss: 9675786.0000\n",
      "Epoch 124/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 10718441.0000 - val_loss: 9616733.0000\n",
      "Epoch 125/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 10651913.0000 - val_loss: 9557617.0000\n",
      "Epoch 126/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 10586596.0000 - val_loss: 9498854.0000\n",
      "Epoch 127/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 10521778.0000 - val_loss: 9441688.0000\n",
      "Epoch 128/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 10457288.0000 - val_loss: 9385269.0000\n",
      "Epoch 129/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 10394274.0000 - val_loss: 9328344.0000\n",
      "Epoch 130/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 10330976.0000 - val_loss: 9272092.0000\n",
      "Epoch 131/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 10268499.0000 - val_loss: 9218046.0000\n",
      "Epoch 132/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 10206975.0000 - val_loss: 9162421.0000\n",
      "Epoch 133/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 10144806.0000 - val_loss: 9108141.0000\n",
      "Epoch 134/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 31ms/step - loss: 10083340.0000 - val_loss: 9052963.0000\n",
      "Epoch 135/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 10021904.0000 - val_loss: 8997538.0000\n",
      "Epoch 136/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 9959803.0000 - val_loss: 8943765.0000\n",
      "Epoch 137/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 9898970.0000 - val_loss: 8890676.0000\n",
      "Epoch 138/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 9838552.0000 - val_loss: 8837012.0000\n",
      "Epoch 139/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 9778652.0000 - val_loss: 8783223.0000\n",
      "Epoch 140/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 9718426.0000 - val_loss: 8730945.0000\n",
      "Epoch 141/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 9659473.0000 - val_loss: 8677887.0000\n",
      "Epoch 142/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 9600725.0000 - val_loss: 8626429.0000\n",
      "Epoch 143/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 9541920.0000 - val_loss: 8574881.0000\n",
      "Epoch 144/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 9483900.0000 - val_loss: 8523996.0000\n",
      "Epoch 145/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 9426044.0000 - val_loss: 8473020.0000\n",
      "Epoch 146/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 9368678.0000 - val_loss: 8422673.0000\n",
      "Epoch 147/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 9311628.0000 - val_loss: 8373654.5000\n",
      "Epoch 148/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 9256208.0000 - val_loss: 8322386.5000\n",
      "Epoch 149/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 9199477.0000 - val_loss: 8274689.5000\n",
      "Epoch 150/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 9144778.0000 - val_loss: 8225721.5000\n",
      "Epoch 151/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 9088952.0000 - val_loss: 8178372.0000\n",
      "Epoch 152/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 9034774.0000 - val_loss: 8130194.5000\n",
      "Epoch 153/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 8980587.0000 - val_loss: 8083085.0000\n",
      "Epoch 154/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 8927261.0000 - val_loss: 8035770.5000\n",
      "Epoch 155/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 8873457.0000 - val_loss: 7989157.5000\n",
      "Epoch 156/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 8819353.0000 - val_loss: 7942118.0000\n",
      "Epoch 157/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 8765731.0000 - val_loss: 7896003.0000\n",
      "Epoch 158/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 8713626.0000 - val_loss: 7850124.0000\n",
      "Epoch 159/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 8661526.0000 - val_loss: 7804525.5000\n",
      "Epoch 160/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 8609150.0000 - val_loss: 7759266.0000\n",
      "Epoch 161/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 8557887.0000 - val_loss: 7714333.5000\n",
      "Epoch 162/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 8507069.0000 - val_loss: 7669894.0000\n",
      "Epoch 163/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 8455773.0000 - val_loss: 7625973.5000\n",
      "Epoch 164/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 8405097.0000 - val_loss: 7582189.5000\n",
      "Epoch 165/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 8355304.5000 - val_loss: 7538501.0000\n",
      "Epoch 166/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 8305485.0000 - val_loss: 7496908.5000\n",
      "Epoch 167/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 8257357.0000 - val_loss: 7453521.0000\n",
      "Epoch 168/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 8207333.5000 - val_loss: 7410885.0000\n",
      "Epoch 169/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 8158556.0000 - val_loss: 7368738.0000\n",
      "Epoch 170/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 8110629.5000 - val_loss: 7327212.0000\n",
      "Epoch 171/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 8062473.0000 - val_loss: 7286423.5000\n",
      "Epoch 172/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 8014849.0000 - val_loss: 7244814.5000\n",
      "Epoch 173/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 7967206.5000 - val_loss: 7203218.5000\n",
      "Epoch 174/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 7919255.5000 - val_loss: 7163656.5000\n",
      "Epoch 175/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 7872431.5000 - val_loss: 7123355.0000\n",
      "Epoch 176/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 7826170.0000 - val_loss: 7082379.5000\n",
      "Epoch 177/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 7779078.0000 - val_loss: 7042132.5000\n",
      "Epoch 178/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 7733301.5000 - val_loss: 7002274.5000\n",
      "Epoch 179/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 7687460.0000 - val_loss: 6963028.5000\n",
      "Epoch 180/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 7641552.5000 - val_loss: 6925567.0000\n",
      "Epoch 181/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 7597349.5000 - val_loss: 6886839.0000\n",
      "Epoch 182/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 7552025.5000 - val_loss: 6847803.0000\n",
      "Epoch 183/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 7507144.0000 - val_loss: 6809143.0000\n",
      "Epoch 184/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 7462628.0000 - val_loss: 6772791.0000\n",
      "Epoch 185/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 7419739.0000 - val_loss: 6735242.0000\n",
      "Epoch 186/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 7375938.5000 - val_loss: 6698426.0000\n",
      "Epoch 187/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 7332986.0000 - val_loss: 6662563.5000\n",
      "Epoch 188/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 7290194.0000 - val_loss: 6626402.5000\n",
      "Epoch 189/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 7247499.5000 - val_loss: 6589382.0000\n",
      "Epoch 190/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 7205157.0000 - val_loss: 6553095.5000\n",
      "Epoch 191/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 7162646.5000 - val_loss: 6518159.5000\n",
      "Epoch 192/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 7120586.0000 - val_loss: 6483240.0000\n",
      "Epoch 193/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 7079717.5000 - val_loss: 6446722.0000\n",
      "Epoch 194/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 7037711.5000 - val_loss: 6413073.0000\n",
      "Epoch 195/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 6997458.0000 - val_loss: 6378772.0000\n",
      "Epoch 196/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 6956681.5000 - val_loss: 6344231.5000\n",
      "Epoch 197/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 6916380.0000 - val_loss: 6309415.0000\n",
      "Epoch 198/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 6875304.0000 - val_loss: 6276262.0000\n",
      "Epoch 199/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 6836272.5000 - val_loss: 6242999.5000\n",
      "Epoch 200/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 6796218.5000 - val_loss: 6210309.0000\n",
      "Epoch 201/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 6757525.0000 - val_loss: 6177785.5000\n",
      "Epoch 202/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 6718781.0000 - val_loss: 6145163.5000\n",
      "Epoch 203/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 6680227.5000 - val_loss: 6113934.0000\n",
      "Epoch 204/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 6642602.0000 - val_loss: 6082209.0000\n",
      "Epoch 205/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 31ms/step - loss: 6604749.5000 - val_loss: 6051358.0000\n",
      "Epoch 206/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 6568205.5000 - val_loss: 6020638.0000\n",
      "Epoch 207/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 6531363.5000 - val_loss: 5990348.5000\n",
      "Epoch 208/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 6494607.0000 - val_loss: 5959462.5000\n",
      "Epoch 209/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 6457681.5000 - val_loss: 5928730.0000\n",
      "Epoch 210/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 6420748.5000 - val_loss: 5898475.5000\n",
      "Epoch 211/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 6384313.5000 - val_loss: 5868554.0000\n",
      "Epoch 212/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 6347721.0000 - val_loss: 5837492.0000\n",
      "Epoch 213/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 6309791.5000 - val_loss: 5807192.5000\n",
      "Epoch 214/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 6272773.5000 - val_loss: 5775969.5000\n",
      "Epoch 215/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 6234733.0000 - val_loss: 5744127.5000\n",
      "Epoch 216/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 6194998.5000 - val_loss: 5710543.0000\n",
      "Epoch 217/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 6154170.0000 - val_loss: 5673366.5000\n",
      "Epoch 218/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 6109231.0000 - val_loss: 5632507.0000\n",
      "Epoch 219/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 6059589.0000 - val_loss: 5585632.0000\n",
      "Epoch 220/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 6006592.0000 - val_loss: 5531171.5000\n",
      "Epoch 221/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5948213.0000 - val_loss: 5476964.0000\n",
      "Epoch 222/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 5889639.5000 - val_loss: 5426483.5000\n",
      "Epoch 223/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 5834909.0000 - val_loss: 5373736.0000\n",
      "Epoch 224/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 5780208.0000 - val_loss: 5325982.0000\n",
      "Epoch 225/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5730522.0000 - val_loss: 5282999.5000\n",
      "Epoch 226/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5683473.5000 - val_loss: 5244482.5000\n",
      "Epoch 227/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 5640148.5000 - val_loss: 5208938.5000\n",
      "Epoch 228/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5598745.5000 - val_loss: 5174974.5000\n",
      "Epoch 229/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5557467.0000 - val_loss: 5141848.5000\n",
      "Epoch 230/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5517951.0000 - val_loss: 5108672.5000\n",
      "Epoch 231/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5478197.5000 - val_loss: 5076370.5000\n",
      "Epoch 232/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 5438926.5000 - val_loss: 5044613.0000\n",
      "Epoch 233/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 5400920.5000 - val_loss: 5013108.0000\n",
      "Epoch 234/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 5363280.0000 - val_loss: 4983062.5000\n",
      "Epoch 235/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5326213.5000 - val_loss: 4952691.0000\n",
      "Epoch 236/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5289762.5000 - val_loss: 4922408.0000\n",
      "Epoch 237/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5253955.5000 - val_loss: 4892445.5000\n",
      "Epoch 238/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5217641.5000 - val_loss: 4862375.5000\n",
      "Epoch 239/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5182545.5000 - val_loss: 4832522.5000\n",
      "Epoch 240/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5147040.5000 - val_loss: 4803348.0000\n",
      "Epoch 241/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5112284.0000 - val_loss: 4775136.5000\n",
      "Epoch 242/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 5077774.0000 - val_loss: 4746623.0000\n",
      "Epoch 243/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 5044222.0000 - val_loss: 4718443.5000\n",
      "Epoch 244/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 5010822.0000 - val_loss: 4690347.0000\n",
      "Epoch 245/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4977387.0000 - val_loss: 4663128.0000\n",
      "Epoch 246/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4944083.5000 - val_loss: 4635219.5000\n",
      "Epoch 247/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4911180.0000 - val_loss: 4606920.5000\n",
      "Epoch 248/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4878002.5000 - val_loss: 4578867.0000\n",
      "Epoch 249/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 4845018.0000 - val_loss: 4552251.5000\n",
      "Epoch 250/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4813586.5000 - val_loss: 4524536.5000\n",
      "Epoch 251/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4781427.5000 - val_loss: 4499224.5000\n",
      "Epoch 252/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4749875.5000 - val_loss: 4471111.5000\n",
      "Epoch 253/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4717539.5000 - val_loss: 4444215.5000\n",
      "Epoch 254/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4685991.5000 - val_loss: 4417185.0000\n",
      "Epoch 255/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4654594.5000 - val_loss: 4391425.5000\n",
      "Epoch 256/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4623976.0000 - val_loss: 4364269.5000\n",
      "Epoch 257/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4592624.0000 - val_loss: 4338859.0000\n",
      "Epoch 258/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 4562152.0000 - val_loss: 4313530.5000\n",
      "Epoch 259/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4531444.5000 - val_loss: 4286761.0000\n",
      "Epoch 260/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4501309.5000 - val_loss: 4261103.5000\n",
      "Epoch 261/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 4471457.5000 - val_loss: 4236053.0000\n",
      "Epoch 262/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4441464.0000 - val_loss: 4208164.5000\n",
      "Epoch 263/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4411486.5000 - val_loss: 4182299.5000\n",
      "Epoch 264/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4381749.5000 - val_loss: 4157884.0000\n",
      "Epoch 265/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4351702.0000 - val_loss: 4131551.2500\n",
      "Epoch 266/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4321467.0000 - val_loss: 4105850.0000\n",
      "Epoch 267/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4292292.5000 - val_loss: 4081257.0000\n",
      "Epoch 268/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4262278.0000 - val_loss: 4054320.7500\n",
      "Epoch 269/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4232056.0000 - val_loss: 4028713.7500\n",
      "Epoch 270/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4202893.0000 - val_loss: 4001493.7500\n",
      "Epoch 271/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4173718.7500 - val_loss: 3977387.5000\n",
      "Epoch 272/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 4144985.5000 - val_loss: 3951798.7500\n",
      "Epoch 273/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4115203.0000 - val_loss: 3924452.2500\n",
      "Epoch 274/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4085829.2500 - val_loss: 3898998.0000\n",
      "Epoch 275/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4057096.0000 - val_loss: 3875038.5000\n",
      "Epoch 276/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 30ms/step - loss: 4029022.7500 - val_loss: 3849690.5000\n",
      "Epoch 277/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4000711.0000 - val_loss: 3824975.2500\n",
      "Epoch 278/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3972122.7500 - val_loss: 3800679.2500\n",
      "Epoch 279/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3943171.5000 - val_loss: 3774202.7500\n",
      "Epoch 280/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3914656.5000 - val_loss: 3749929.7500\n",
      "Epoch 281/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 3887173.2500 - val_loss: 3725382.5000\n",
      "Epoch 282/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3859740.0000 - val_loss: 3702939.5000\n",
      "Epoch 283/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3831407.0000 - val_loss: 3678186.2500\n",
      "Epoch 284/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3804161.7500 - val_loss: 3653218.7500\n",
      "Epoch 285/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3777085.7500 - val_loss: 3631011.2500\n",
      "Epoch 286/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3749559.2500 - val_loss: 3606815.0000\n",
      "Epoch 287/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3722760.0000 - val_loss: 3582427.2500\n",
      "Epoch 288/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3696566.7500 - val_loss: 3557451.0000\n",
      "Epoch 289/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 3669149.0000 - val_loss: 3535182.5000\n",
      "Epoch 290/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 3642551.2500 - val_loss: 3513334.7500\n",
      "Epoch 291/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 3616216.5000 - val_loss: 3490596.0000\n",
      "Epoch 292/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3590279.0000 - val_loss: 3467834.5000\n",
      "Epoch 293/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3564406.7500 - val_loss: 3445157.2500\n",
      "Epoch 294/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3538501.5000 - val_loss: 3421817.5000\n",
      "Epoch 295/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3513928.2500 - val_loss: 3398969.7500\n",
      "Epoch 296/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3489204.0000 - val_loss: 3380068.7500\n",
      "Epoch 297/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3464223.0000 - val_loss: 3358119.5000\n",
      "Epoch 298/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 3439974.5000 - val_loss: 3336550.0000\n",
      "Epoch 299/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3416608.5000 - val_loss: 3315623.2500\n",
      "Epoch 300/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3391805.2500 - val_loss: 3292812.7500\n",
      "Epoch 301/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3368411.2500 - val_loss: 3272630.2500\n",
      "Epoch 302/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3344940.7500 - val_loss: 3250870.5000\n",
      "Epoch 303/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3321536.0000 - val_loss: 3230834.5000\n",
      "Epoch 304/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3297931.2500 - val_loss: 3211126.2500\n",
      "Epoch 305/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3275593.0000 - val_loss: 3188574.0000\n",
      "Epoch 306/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 3252541.0000 - val_loss: 3168834.5000\n",
      "Epoch 307/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 3230676.5000 - val_loss: 3148699.7500\n",
      "Epoch 308/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3208338.7500 - val_loss: 3125949.5000\n",
      "Epoch 309/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3186157.7500 - val_loss: 3105304.5000\n",
      "Epoch 310/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3163281.0000 - val_loss: 3083613.2500\n",
      "Epoch 311/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3142023.2500 - val_loss: 3064861.5000\n",
      "Epoch 312/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3119519.0000 - val_loss: 3046406.5000\n",
      "Epoch 313/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3098635.7500 - val_loss: 3025735.5000\n",
      "Epoch 314/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3077256.0000 - val_loss: 3001495.5000\n",
      "Epoch 315/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 3055804.0000 - val_loss: 2987078.7500\n",
      "Epoch 316/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 3033801.0000 - val_loss: 2968400.0000\n",
      "Epoch 317/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 3012404.0000 - val_loss: 2948058.0000\n",
      "Epoch 318/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2992380.5000 - val_loss: 2924241.5000\n",
      "Epoch 319/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2970866.7500 - val_loss: 2907223.5000\n",
      "Epoch 320/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2950452.7500 - val_loss: 2888681.2500\n",
      "Epoch 321/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2929339.5000 - val_loss: 2868501.5000\n",
      "Epoch 322/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2909143.7500 - val_loss: 2851955.5000\n",
      "Epoch 323/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2889380.2500 - val_loss: 2831073.5000\n",
      "Epoch 324/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2868421.5000 - val_loss: 2811780.2500\n",
      "Epoch 325/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 2848723.2500 - val_loss: 2791331.7500\n",
      "Epoch 326/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2829295.2500 - val_loss: 2774551.0000\n",
      "Epoch 327/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2809032.7500 - val_loss: 2755770.7500\n",
      "Epoch 328/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2789561.0000 - val_loss: 2737276.5000\n",
      "Epoch 329/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2769797.2500 - val_loss: 2718965.7500\n",
      "Epoch 330/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2750656.0000 - val_loss: 2697401.7500\n",
      "Epoch 331/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2732202.0000 - val_loss: 2681368.5000\n",
      "Epoch 332/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2712201.7500 - val_loss: 2661078.7500\n",
      "Epoch 333/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2693750.5000 - val_loss: 2643258.0000\n",
      "Epoch 334/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 2675072.2500 - val_loss: 2625104.0000\n",
      "Epoch 335/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2656365.2500 - val_loss: 2608048.0000\n",
      "Epoch 336/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2638263.7500 - val_loss: 2590010.0000\n",
      "Epoch 337/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2620035.7500 - val_loss: 2569285.2500\n",
      "Epoch 338/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 2602758.0000 - val_loss: 2549984.7500\n",
      "Epoch 339/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2584811.7500 - val_loss: 2533308.5000\n",
      "Epoch 340/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2566225.7500 - val_loss: 2517384.0000\n",
      "Epoch 341/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2548556.2500 - val_loss: 2502073.5000\n",
      "Epoch 342/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2531076.5000 - val_loss: 2482818.2500\n",
      "Epoch 343/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2513986.2500 - val_loss: 2465690.2500\n",
      "Epoch 344/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2496809.7500 - val_loss: 2452462.2500\n",
      "Epoch 345/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2480304.7500 - val_loss: 2438084.0000\n",
      "Epoch 346/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2463518.0000 - val_loss: 2419329.7500\n",
      "Epoch 347/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 30ms/step - loss: 2447111.0000 - val_loss: 2401086.0000\n",
      "Epoch 348/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2430635.2500 - val_loss: 2382266.0000\n",
      "Epoch 349/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2414396.2500 - val_loss: 2371648.0000\n",
      "Epoch 350/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2397484.2500 - val_loss: 2352411.7500\n",
      "Epoch 351/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2381791.7500 - val_loss: 2338743.2500\n",
      "Epoch 352/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 2365695.5000 - val_loss: 2320668.5000\n",
      "Epoch 353/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2350173.2500 - val_loss: 2311301.7500\n",
      "Epoch 354/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2334458.0000 - val_loss: 2291441.5000\n",
      "Epoch 355/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2319121.0000 - val_loss: 2272468.0000\n",
      "Epoch 356/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2303389.5000 - val_loss: 2258304.7500\n",
      "Epoch 357/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2288582.7500 - val_loss: 2247554.0000\n",
      "Epoch 358/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2272975.2500 - val_loss: 2231000.5000\n",
      "Epoch 359/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2257417.0000 - val_loss: 2213349.0000\n",
      "Epoch 360/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2243049.0000 - val_loss: 2198880.7500\n",
      "Epoch 361/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 2228138.7500 - val_loss: 2185796.2500\n",
      "Epoch 362/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 2213618.5000 - val_loss: 2172335.7500\n",
      "Epoch 363/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 2199098.5000 - val_loss: 2157973.5000\n",
      "Epoch 364/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 2184515.7500 - val_loss: 2141572.2500\n",
      "Epoch 365/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 2170199.5000 - val_loss: 2127997.7500\n",
      "Epoch 366/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 2156707.5000 - val_loss: 2112052.7500\n",
      "Epoch 367/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 2142098.5000 - val_loss: 2101897.2500\n",
      "Epoch 368/1000\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 2128223.2500 - val_loss: 2086344.0000\n",
      "Epoch 369/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 2115183.0000 - val_loss: 2075880.8750\n",
      "Epoch 370/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 2101124.7500 - val_loss: 2058178.6250\n",
      "Epoch 371/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 2087932.7500 - val_loss: 2044286.7500\n",
      "Epoch 372/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 2074608.6250 - val_loss: 2031864.0000\n",
      "Epoch 373/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 2061800.7500 - val_loss: 2022092.2500\n",
      "Epoch 374/1000\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 2047928.3750 - val_loss: 2006045.6250\n",
      "Epoch 375/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 2034914.0000 - val_loss: 1995751.0000\n",
      "Epoch 376/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2021650.3750 - val_loss: 1982704.5000\n",
      "Epoch 377/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 2009159.0000 - val_loss: 1968826.7500\n",
      "Epoch 378/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1996092.7500 - val_loss: 1957815.5000\n",
      "Epoch 379/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1983618.2500 - val_loss: 1947324.2500\n",
      "Epoch 380/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1970919.8750 - val_loss: 1934652.5000\n",
      "Epoch 381/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1959156.1250 - val_loss: 1919875.7500\n",
      "Epoch 382/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1946465.5000 - val_loss: 1908903.0000\n",
      "Epoch 383/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1933797.2500 - val_loss: 1896320.8750\n",
      "Epoch 384/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1921541.5000 - val_loss: 1883042.3750\n",
      "Epoch 385/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1909185.3750 - val_loss: 1874016.3750\n",
      "Epoch 386/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1897572.3750 - val_loss: 1861342.7500\n",
      "Epoch 387/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1885883.8750 - val_loss: 1849388.0000\n",
      "Epoch 388/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1874092.2500 - val_loss: 1838374.3750\n",
      "Epoch 389/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1863092.8750 - val_loss: 1827928.0000\n",
      "Epoch 390/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1851581.1250 - val_loss: 1812337.0000\n",
      "Epoch 391/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1839330.8750 - val_loss: 1803337.1250\n",
      "Epoch 392/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1828192.8750 - val_loss: 1793063.3750\n",
      "Epoch 393/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1816658.0000 - val_loss: 1781153.1250\n",
      "Epoch 394/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1805938.7500 - val_loss: 1773498.5000\n",
      "Epoch 395/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1794693.8750 - val_loss: 1759586.1250\n",
      "Epoch 396/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1783404.2500 - val_loss: 1749012.6250\n",
      "Epoch 397/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1772816.0000 - val_loss: 1738641.2500\n",
      "Epoch 398/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1762187.1250 - val_loss: 1727954.1250\n",
      "Epoch 399/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1751882.7500 - val_loss: 1719339.1250\n",
      "Epoch 400/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1740668.1250 - val_loss: 1706346.5000\n",
      "Epoch 401/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1730699.1250 - val_loss: 1692723.6250\n",
      "Epoch 402/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1719955.3750 - val_loss: 1685493.6250\n",
      "Epoch 403/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1709472.5000 - val_loss: 1676245.7500\n",
      "Epoch 404/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1699081.1250 - val_loss: 1663928.8750\n",
      "Epoch 405/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1688805.3750 - val_loss: 1655535.5000\n",
      "Epoch 406/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1678496.2500 - val_loss: 1645611.1250\n",
      "Epoch 407/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1668635.8750 - val_loss: 1636384.0000\n",
      "Epoch 408/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1658051.1250 - val_loss: 1625524.3750\n",
      "Epoch 409/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1648009.7500 - val_loss: 1614575.2500\n",
      "Epoch 410/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1638570.5000 - val_loss: 1607685.5000\n",
      "Epoch 411/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1628551.0000 - val_loss: 1595877.7500\n",
      "Epoch 412/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1618999.5000 - val_loss: 1587802.6250\n",
      "Epoch 413/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1609571.1250 - val_loss: 1579082.2500\n",
      "Epoch 414/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1599983.5000 - val_loss: 1570587.3750\n",
      "Epoch 415/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1590904.1250 - val_loss: 1558389.0000\n",
      "Epoch 416/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1581088.0000 - val_loss: 1552676.5000\n",
      "Epoch 417/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1571473.8750 - val_loss: 1542478.7500\n",
      "Epoch 418/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 31ms/step - loss: 1562212.1250 - val_loss: 1533584.7500\n",
      "Epoch 419/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1553097.1250 - val_loss: 1523529.5000\n",
      "Epoch 420/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1545155.5000 - val_loss: 1519551.1250\n",
      "Epoch 421/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1535165.7500 - val_loss: 1505789.7500\n",
      "Epoch 422/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1526424.6250 - val_loss: 1496145.3750\n",
      "Epoch 423/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1517809.1250 - val_loss: 1490378.1250\n",
      "Epoch 424/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1508943.0000 - val_loss: 1481937.3750\n",
      "Epoch 425/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1499743.5000 - val_loss: 1472934.3750\n",
      "Epoch 426/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1491190.5000 - val_loss: 1464477.8750\n",
      "Epoch 427/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1482152.0000 - val_loss: 1456089.0000\n",
      "Epoch 428/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1475348.8750 - val_loss: 1444419.2500\n",
      "Epoch 429/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1465152.3750 - val_loss: 1438657.8750\n",
      "Epoch 430/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1457061.6250 - val_loss: 1432672.6250\n",
      "Epoch 431/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1450008.8750 - val_loss: 1427800.2500\n",
      "Epoch 432/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1441309.8750 - val_loss: 1417899.1250\n",
      "Epoch 433/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1432371.0000 - val_loss: 1409709.5000\n",
      "Epoch 434/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1424360.5000 - val_loss: 1402482.2500\n",
      "Epoch 435/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1416307.1250 - val_loss: 1396537.6250\n",
      "Epoch 436/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1408364.1250 - val_loss: 1387485.0000\n",
      "Epoch 437/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1400897.2500 - val_loss: 1381536.5000\n",
      "Epoch 438/1000\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 1392302.7500 - val_loss: 1372581.2500\n",
      "Epoch 439/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1384460.7500 - val_loss: 1366260.5000\n",
      "Epoch 440/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1376899.1250 - val_loss: 1359254.1250\n",
      "Epoch 441/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1369617.0000 - val_loss: 1348699.1250\n",
      "Epoch 442/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1361832.1250 - val_loss: 1341387.7500\n",
      "Epoch 443/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1353982.6250 - val_loss: 1335875.6250\n",
      "Epoch 444/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1347073.8750 - val_loss: 1331066.5000\n",
      "Epoch 445/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1339324.0000 - val_loss: 1322468.0000\n",
      "Epoch 446/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1332146.2500 - val_loss: 1316786.7500\n",
      "Epoch 447/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1324847.3750 - val_loss: 1310835.0000\n",
      "Epoch 448/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1317685.2500 - val_loss: 1303434.7500\n",
      "Epoch 449/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1310409.1250 - val_loss: 1294268.7500\n",
      "Epoch 450/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1303363.2500 - val_loss: 1288494.6250\n",
      "Epoch 451/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1297195.6250 - val_loss: 1283562.5000\n",
      "Epoch 452/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1289139.3750 - val_loss: 1276098.1250\n",
      "Epoch 453/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1282294.5000 - val_loss: 1267964.7500\n",
      "Epoch 454/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1275494.6250 - val_loss: 1262107.5000\n",
      "Epoch 455/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1268541.3750 - val_loss: 1256492.6250\n",
      "Epoch 456/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1261628.7500 - val_loss: 1252078.6250\n",
      "Epoch 457/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1254783.7500 - val_loss: 1244365.7500\n",
      "Epoch 458/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1248268.8750 - val_loss: 1238223.6250\n",
      "Epoch 459/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1241496.5000 - val_loss: 1231376.3750\n",
      "Epoch 460/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1234680.6250 - val_loss: 1225803.3750\n",
      "Epoch 461/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1228240.8750 - val_loss: 1219870.7500\n",
      "Epoch 462/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1221813.7500 - val_loss: 1214355.7500\n",
      "Epoch 463/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1215329.7500 - val_loss: 1209511.7500\n",
      "Epoch 464/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1208937.7500 - val_loss: 1202916.1250\n",
      "Epoch 465/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1202244.7500 - val_loss: 1196380.6250\n",
      "Epoch 466/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1196001.1250 - val_loss: 1190326.6250\n",
      "Epoch 467/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1189837.6250 - val_loss: 1186587.2500\n",
      "Epoch 468/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1183982.1250 - val_loss: 1181308.6250\n",
      "Epoch 469/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1177777.1250 - val_loss: 1171355.8750\n",
      "Epoch 470/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1170625.0000 - val_loss: 1166648.7500\n",
      "Epoch 471/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1164064.2500 - val_loss: 1163389.0000\n",
      "Epoch 472/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1158160.3750 - val_loss: 1159135.3750\n",
      "Epoch 473/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1151935.7500 - val_loss: 1150848.5000\n",
      "Epoch 474/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1145993.1250 - val_loss: 1146040.7500\n",
      "Epoch 475/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1140178.2500 - val_loss: 1137426.8750\n",
      "Epoch 476/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1134387.1250 - val_loss: 1133353.7500\n",
      "Epoch 477/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1128228.0000 - val_loss: 1128249.5000\n",
      "Epoch 478/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1122800.8750 - val_loss: 1120252.7500\n",
      "Epoch 479/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1116744.5000 - val_loss: 1118090.0000\n",
      "Epoch 480/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1110204.8750 - val_loss: 1112242.7500\n",
      "Epoch 481/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1104315.2500 - val_loss: 1106609.5000\n",
      "Epoch 482/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1098418.1250 - val_loss: 1100343.3750\n",
      "Epoch 483/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1092573.2500 - val_loss: 1096269.2500\n",
      "Epoch 484/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1087025.8750 - val_loss: 1089323.1250\n",
      "Epoch 485/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1080933.8750 - val_loss: 1084535.1250\n",
      "Epoch 486/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1074979.1250 - val_loss: 1080455.0000\n",
      "Epoch 487/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1069107.1250 - val_loss: 1075786.5000\n",
      "Epoch 488/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1063458.7500 - val_loss: 1067716.1250\n",
      "Epoch 489/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 32ms/step - loss: 1057555.8750 - val_loss: 1062174.7500\n",
      "Epoch 490/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1052227.5000 - val_loss: 1056479.7500\n",
      "Epoch 491/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1046775.6875 - val_loss: 1052230.7500\n",
      "Epoch 492/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1040757.5000 - val_loss: 1047518.5000\n",
      "Epoch 493/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1035310.6875 - val_loss: 1042840.6250\n",
      "Epoch 494/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1029893.9375 - val_loss: 1037777.0625\n",
      "Epoch 495/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1024554.4375 - val_loss: 1030924.0000\n",
      "Epoch 496/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1019419.8125 - val_loss: 1026334.0625\n",
      "Epoch 497/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1014848.4375 - val_loss: 1020899.3750\n",
      "Epoch 498/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1008573.6875 - val_loss: 1017388.3125\n",
      "Epoch 499/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1002862.6875 - val_loss: 1012167.0625\n",
      "Epoch 500/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 997361.8750 - val_loss: 1008288.0000\n",
      "Epoch 501/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 992136.1250 - val_loss: 1003351.8125\n",
      "Epoch 502/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 986794.3125 - val_loss: 998237.3750\n",
      "Epoch 503/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 981648.0000 - val_loss: 993439.8125\n",
      "Epoch 504/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 977404.6250 - val_loss: 986992.3125\n",
      "Epoch 505/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 971697.1875 - val_loss: 983444.4375\n",
      "Epoch 506/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 966886.4375 - val_loss: 979392.0000\n",
      "Epoch 507/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 961631.4375 - val_loss: 973093.0000\n",
      "Epoch 508/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 956874.1875 - val_loss: 966778.4375\n",
      "Epoch 509/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 951914.1875 - val_loss: 961734.6250\n",
      "Epoch 510/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 946967.3125 - val_loss: 956677.8750\n",
      "Epoch 511/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 941740.3750 - val_loss: 951385.2500\n",
      "Epoch 512/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 937275.6250 - val_loss: 948794.3125\n",
      "Epoch 513/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 933012.6250 - val_loss: 939348.4375\n",
      "Epoch 514/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 927283.9375 - val_loss: 936805.6875\n",
      "Epoch 515/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 922575.8750 - val_loss: 934424.9375\n",
      "Epoch 516/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 916912.3750 - val_loss: 928993.0000\n",
      "Epoch 517/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 912240.0000 - val_loss: 923568.3125\n",
      "Epoch 518/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 907983.5000 - val_loss: 918567.8125\n",
      "Epoch 519/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 903445.5625 - val_loss: 915155.9375\n",
      "Epoch 520/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 898802.6875 - val_loss: 910279.2500\n",
      "Epoch 521/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 893689.8750 - val_loss: 907770.0000\n",
      "Epoch 522/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 889879.1250 - val_loss: 905075.5000\n",
      "Epoch 523/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 885302.1250 - val_loss: 898007.8125\n",
      "Epoch 524/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 880650.8750 - val_loss: 894287.8750\n",
      "Epoch 525/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 876282.0000 - val_loss: 890410.8125\n",
      "Epoch 526/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 871841.4375 - val_loss: 886006.1250\n",
      "Epoch 527/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 867729.4375 - val_loss: 882548.6875\n",
      "Epoch 528/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 863218.0000 - val_loss: 878322.3750\n",
      "Epoch 529/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 858848.3125 - val_loss: 874439.0000\n",
      "Epoch 530/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 854435.1250 - val_loss: 869814.9375\n",
      "Epoch 531/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 850459.1250 - val_loss: 864461.2500\n",
      "Epoch 532/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 845928.6875 - val_loss: 860395.6875\n",
      "Epoch 533/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 841833.4375 - val_loss: 856573.3125\n",
      "Epoch 534/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 837603.5625 - val_loss: 852992.6875\n",
      "Epoch 535/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 833509.1250 - val_loss: 849307.8750\n",
      "Epoch 536/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 829549.3750 - val_loss: 845764.7500\n",
      "Epoch 537/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 825475.6875 - val_loss: 842433.8125\n",
      "Epoch 538/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 821004.8750 - val_loss: 837542.1875\n",
      "Epoch 539/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 817075.5625 - val_loss: 834555.3125\n",
      "Epoch 540/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 812983.5625 - val_loss: 828983.5000\n",
      "Epoch 541/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 808932.5000 - val_loss: 824147.9375\n",
      "Epoch 542/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 805871.7500 - val_loss: 821254.5000\n",
      "Epoch 543/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 801557.5000 - val_loss: 815112.6875\n",
      "Epoch 544/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 797489.0000 - val_loss: 811881.9375\n",
      "Epoch 545/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 793693.8750 - val_loss: 809873.0625\n",
      "Epoch 546/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 790319.5000 - val_loss: 806351.3750\n",
      "Epoch 547/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 786356.8750 - val_loss: 804720.1875\n",
      "Epoch 548/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 782832.1875 - val_loss: 799046.6875\n",
      "Epoch 549/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 778784.8750 - val_loss: 795397.1250\n",
      "Epoch 550/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 774997.6875 - val_loss: 790869.5000\n",
      "Epoch 551/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 771339.2500 - val_loss: 785818.1250\n",
      "Epoch 552/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 767754.3750 - val_loss: 783442.8125\n",
      "Epoch 553/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 763991.3125 - val_loss: 779057.3125\n",
      "Epoch 554/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 760347.5625 - val_loss: 775428.3750\n",
      "Epoch 555/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 756726.8750 - val_loss: 773040.6875\n",
      "Epoch 556/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 753325.8750 - val_loss: 769955.3125\n",
      "Epoch 557/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 749842.1250 - val_loss: 766304.3750\n",
      "Epoch 558/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 746523.7500 - val_loss: 763368.0000\n",
      "Epoch 559/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 743783.4375 - val_loss: 759220.4375\n",
      "Epoch 560/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 739872.8750 - val_loss: 755312.6875\n",
      "Epoch 561/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 31ms/step - loss: 736361.9375 - val_loss: 752354.6250\n",
      "Epoch 562/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 733188.5000 - val_loss: 749927.3750\n",
      "Epoch 563/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 730197.3750 - val_loss: 745831.1250\n",
      "Epoch 564/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 727206.6250 - val_loss: 742380.1250\n",
      "Epoch 565/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 723717.1250 - val_loss: 738040.1875\n",
      "Epoch 566/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 720920.0625 - val_loss: 734967.0000\n",
      "Epoch 567/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 717769.2500 - val_loss: 732901.9375\n",
      "Epoch 568/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 714614.1875 - val_loss: 731093.5625\n",
      "Epoch 569/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 711538.5625 - val_loss: 728756.5000\n",
      "Epoch 570/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 708639.6875 - val_loss: 726405.2500\n",
      "Epoch 571/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 705834.3750 - val_loss: 721912.0000\n",
      "Epoch 572/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 703396.5625 - val_loss: 719713.0000\n",
      "Epoch 573/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 699804.3750 - val_loss: 715779.7500\n",
      "Epoch 574/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 697030.3750 - val_loss: 711809.5000\n",
      "Epoch 575/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 695056.4375 - val_loss: 708394.8125\n",
      "Epoch 576/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 691533.5625 - val_loss: 707768.3750\n",
      "Epoch 577/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 689088.4375 - val_loss: 705643.1250\n",
      "Epoch 578/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 686811.0000 - val_loss: 704987.2500\n",
      "Epoch 579/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 683860.5000 - val_loss: 697324.8125\n",
      "Epoch 580/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 680943.7500 - val_loss: 695582.1250\n",
      "Epoch 581/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 678331.9375 - val_loss: 695129.5000\n",
      "Epoch 582/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 675874.3125 - val_loss: 693098.3125\n",
      "Epoch 583/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 673534.7500 - val_loss: 688143.2500\n",
      "Epoch 584/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 670822.1250 - val_loss: 686195.5625\n",
      "Epoch 585/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 668313.5625 - val_loss: 684511.3750\n",
      "Epoch 586/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 665900.6875 - val_loss: 682304.2500\n",
      "Epoch 587/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 663594.6875 - val_loss: 679532.9375\n",
      "Epoch 588/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 661090.9375 - val_loss: 677347.6875\n",
      "Epoch 589/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 658746.6250 - val_loss: 672599.0000\n",
      "Epoch 590/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 656526.4375 - val_loss: 670720.5000\n",
      "Epoch 591/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 654209.1250 - val_loss: 666866.1250\n",
      "Epoch 592/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 652321.6875 - val_loss: 664798.1875\n",
      "Epoch 593/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 649809.2500 - val_loss: 661651.1875\n",
      "Epoch 594/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 647224.4375 - val_loss: 660247.1875\n",
      "Epoch 595/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 644929.3125 - val_loss: 658298.0000\n",
      "Epoch 596/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 642856.6875 - val_loss: 658711.6875\n",
      "Epoch 597/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 641073.5625 - val_loss: 655068.0000\n",
      "Epoch 598/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 638203.8125 - val_loss: 653593.5625\n",
      "Epoch 599/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 636135.5625 - val_loss: 651169.0000\n",
      "Epoch 600/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 634163.3125 - val_loss: 648592.6250\n",
      "Epoch 601/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 632284.5000 - val_loss: 647430.5000\n",
      "Epoch 602/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 629859.3125 - val_loss: 644526.6875\n",
      "Epoch 603/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 627992.1875 - val_loss: 641248.2500\n",
      "Epoch 604/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 626036.0000 - val_loss: 638194.2500\n",
      "Epoch 605/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 623997.1250 - val_loss: 637097.0625\n",
      "Epoch 606/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 622029.1250 - val_loss: 635936.1250\n",
      "Epoch 607/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 620768.5000 - val_loss: 636470.1875\n",
      "Epoch 608/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 618200.8750 - val_loss: 631937.5000\n",
      "Epoch 609/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 616557.6875 - val_loss: 628356.6250\n",
      "Epoch 610/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 614479.7500 - val_loss: 628156.6875\n",
      "Epoch 611/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 613053.5000 - val_loss: 624696.0625\n",
      "Epoch 612/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 611739.5625 - val_loss: 623098.7500\n",
      "Epoch 613/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 609504.2500 - val_loss: 622333.2500\n",
      "Epoch 614/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 607667.5625 - val_loss: 620796.1875\n",
      "Epoch 615/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 606049.2500 - val_loss: 618820.8125\n",
      "Epoch 616/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 604203.1875 - val_loss: 617699.7500\n",
      "Epoch 617/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 603117.8125 - val_loss: 617038.5625\n",
      "Epoch 618/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 600949.6875 - val_loss: 614621.6875\n",
      "Epoch 619/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 599673.0000 - val_loss: 611175.1250\n",
      "Epoch 620/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 597983.3750 - val_loss: 610567.8125\n",
      "Epoch 621/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 596233.1875 - val_loss: 609556.6875\n",
      "Epoch 622/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 595347.1250 - val_loss: 607043.1875\n",
      "Epoch 623/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 593066.1875 - val_loss: 607384.1250\n",
      "Epoch 624/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 591552.8125 - val_loss: 605480.9375\n",
      "Epoch 625/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 590285.0000 - val_loss: 604099.3125\n",
      "Epoch 626/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 588989.7500 - val_loss: 600608.9375\n",
      "Epoch 627/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 587443.3125 - val_loss: 600423.0625\n",
      "Epoch 628/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 585573.6250 - val_loss: 600890.8125\n",
      "Epoch 629/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 584693.6875 - val_loss: 599803.3125\n",
      "Epoch 630/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 582521.1875 - val_loss: 596564.0625\n",
      "Epoch 631/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 581018.6250 - val_loss: 595575.1875\n",
      "Epoch 632/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 579171.2500 - val_loss: 592182.8125\n",
      "Epoch 633/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 31ms/step - loss: 577699.7500 - val_loss: 592544.6250\n",
      "Epoch 634/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 576465.8125 - val_loss: 589679.3750\n",
      "Epoch 635/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 574610.3125 - val_loss: 588712.5000\n",
      "Epoch 636/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 573020.0000 - val_loss: 586864.9375\n",
      "Epoch 637/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 571823.0625 - val_loss: 585076.2500\n",
      "Epoch 638/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 570231.6875 - val_loss: 582522.9375\n",
      "Epoch 639/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 568904.2500 - val_loss: 582782.3125\n",
      "Epoch 640/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 567797.1875 - val_loss: 581705.0625\n",
      "Epoch 641/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 566647.8125 - val_loss: 579932.1250\n",
      "Epoch 642/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 566354.0000 - val_loss: 576015.6250\n",
      "Epoch 643/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 563881.2500 - val_loss: 575806.9375\n",
      "Epoch 644/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 562273.0625 - val_loss: 575481.1250\n",
      "Epoch 645/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 561377.9375 - val_loss: 577221.0000\n",
      "Epoch 646/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 559565.8125 - val_loss: 572802.5000\n",
      "Epoch 647/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 559189.9375 - val_loss: 568442.7500\n",
      "Epoch 648/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 557670.4375 - val_loss: 568073.2500\n",
      "Epoch 649/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 556053.5625 - val_loss: 569453.6250\n",
      "Epoch 650/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 554916.5625 - val_loss: 569286.5625\n",
      "Epoch 651/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 554315.0625 - val_loss: 566383.3750\n",
      "Epoch 652/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 552460.7500 - val_loss: 565687.0625\n",
      "Epoch 653/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 551703.6250 - val_loss: 566637.8125\n",
      "Epoch 654/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 550673.5625 - val_loss: 567685.7500\n",
      "Epoch 655/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 549431.1875 - val_loss: 565010.8125\n",
      "Epoch 656/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 548049.7500 - val_loss: 563500.6250\n",
      "Epoch 657/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 546927.5625 - val_loss: 561020.6250\n",
      "Epoch 658/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 546159.3125 - val_loss: 559214.6250\n",
      "Epoch 659/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 545072.1875 - val_loss: 558972.6875\n",
      "Epoch 660/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 544837.8750 - val_loss: 555926.9375\n",
      "Epoch 661/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 543434.3125 - val_loss: 556746.5000\n",
      "Epoch 662/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 541887.0625 - val_loss: 558327.7500\n",
      "Epoch 663/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 540955.3125 - val_loss: 556080.9375\n",
      "Epoch 664/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 540579.0625 - val_loss: 551945.2500\n",
      "Epoch 665/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 539684.8125 - val_loss: 550597.5000\n",
      "Epoch 666/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 538470.4375 - val_loss: 550691.6250\n",
      "Epoch 667/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 537607.8125 - val_loss: 550514.3750\n",
      "Epoch 668/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 536420.4375 - val_loss: 549531.1875\n",
      "Epoch 669/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 535587.1250 - val_loss: 548427.3125\n",
      "Epoch 670/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 535053.1250 - val_loss: 546514.9375\n",
      "Epoch 671/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 534214.5000 - val_loss: 549077.0000\n",
      "Epoch 672/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 533657.5625 - val_loss: 544553.2500\n",
      "Epoch 673/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 532120.4375 - val_loss: 543990.0000\n",
      "Epoch 674/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 530917.6875 - val_loss: 544255.4375\n",
      "Epoch 675/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 530264.1250 - val_loss: 546755.1875\n",
      "Epoch 676/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 529685.4375 - val_loss: 544287.0000\n",
      "Epoch 677/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 528687.2500 - val_loss: 543181.6875\n",
      "Epoch 678/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 527479.5000 - val_loss: 541579.1875\n",
      "Epoch 679/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 526820.5625 - val_loss: 540281.2500\n",
      "Epoch 680/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 526031.4375 - val_loss: 539790.1250\n",
      "Epoch 681/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 525115.3750 - val_loss: 537460.0000\n",
      "Epoch 682/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 524617.6250 - val_loss: 535942.9375\n",
      "Epoch 683/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 523598.7812 - val_loss: 538225.9375\n",
      "Epoch 684/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 522631.4062 - val_loss: 536801.9375\n",
      "Epoch 685/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 521952.3750 - val_loss: 536541.3125\n",
      "Epoch 686/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 520895.7812 - val_loss: 534730.9375\n",
      "Epoch 687/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 520184.2812 - val_loss: 533093.1250\n",
      "Epoch 688/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 519996.2812 - val_loss: 534864.2500\n",
      "Epoch 689/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 518859.7188 - val_loss: 533228.1250\n",
      "Epoch 690/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 518380.3438 - val_loss: 530952.0000\n",
      "Epoch 691/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 517076.8125 - val_loss: 530519.0000\n",
      "Epoch 692/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 516549.3125 - val_loss: 529899.0625\n",
      "Epoch 693/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 515641.3125 - val_loss: 528434.6875\n",
      "Epoch 694/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 515056.1250 - val_loss: 527578.2500\n",
      "Epoch 695/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 514486.6875 - val_loss: 525840.1875\n",
      "Epoch 696/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 513638.9688 - val_loss: 525459.2500\n",
      "Epoch 697/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 513454.4062 - val_loss: 523700.9062\n",
      "Epoch 698/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 512335.2188 - val_loss: 524030.6875\n",
      "Epoch 699/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 511601.0938 - val_loss: 524914.0625\n",
      "Epoch 700/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 510773.3750 - val_loss: 525719.7500\n",
      "Epoch 701/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 510429.5938 - val_loss: 523999.4062\n",
      "Epoch 702/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 509397.2188 - val_loss: 524444.2500\n",
      "Epoch 703/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 508598.5312 - val_loss: 522648.1562\n",
      "Epoch 704/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 508054.2500 - val_loss: 521604.5312\n",
      "Epoch 705/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 31ms/step - loss: 507384.3750 - val_loss: 521935.7812\n",
      "Epoch 706/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 507110.0938 - val_loss: 523510.3125\n",
      "Epoch 707/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 505952.7188 - val_loss: 521094.9688\n",
      "Epoch 708/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 505565.4375 - val_loss: 521308.3125\n",
      "Epoch 709/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 504670.0938 - val_loss: 520563.2500\n",
      "Epoch 710/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 504046.3438 - val_loss: 521013.5625\n",
      "Epoch 711/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 503460.8750 - val_loss: 520543.2812\n",
      "Epoch 712/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 503435.7188 - val_loss: 519317.1562\n",
      "Epoch 713/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 502577.6562 - val_loss: 519260.0938\n",
      "Epoch 714/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 501749.7500 - val_loss: 516553.6250\n",
      "Epoch 715/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 500847.5000 - val_loss: 517986.8750\n",
      "Epoch 716/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 500626.8438 - val_loss: 517759.8438\n",
      "Epoch 717/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 499791.2188 - val_loss: 517505.2500\n",
      "Epoch 718/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 499712.3438 - val_loss: 518535.1875\n",
      "Epoch 719/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 499105.0312 - val_loss: 516996.2500\n",
      "Epoch 720/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 498533.4688 - val_loss: 514961.8438\n",
      "Epoch 721/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 498013.4375 - val_loss: 513393.7812\n",
      "Epoch 722/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 497357.2188 - val_loss: 513331.1562\n",
      "Epoch 723/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 496652.3438 - val_loss: 512707.5938\n",
      "Epoch 724/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 496172.3438 - val_loss: 513633.7812\n",
      "Epoch 725/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 496355.9375 - val_loss: 511504.0625\n",
      "Epoch 726/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 495050.9688 - val_loss: 511782.0938\n",
      "Epoch 727/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 494881.2500 - val_loss: 510479.9062\n",
      "Epoch 728/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 494043.8750 - val_loss: 510546.4375\n",
      "Epoch 729/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 493864.3750 - val_loss: 510681.5312\n",
      "Epoch 730/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 493924.8125 - val_loss: 512378.1250\n",
      "Epoch 731/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 492620.0000 - val_loss: 510175.4688\n",
      "Epoch 732/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 492085.7500 - val_loss: 509951.0625\n",
      "Epoch 733/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 492060.0000 - val_loss: 506292.9375\n",
      "Epoch 734/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 491187.1875 - val_loss: 507423.9375\n",
      "Epoch 735/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 490690.3125 - val_loss: 508752.7500\n",
      "Epoch 736/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 490584.7188 - val_loss: 508605.9375\n",
      "Epoch 737/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 490138.4688 - val_loss: 509002.9375\n",
      "Epoch 738/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 489335.1250 - val_loss: 505165.2188\n",
      "Epoch 739/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 490593.2188 - val_loss: 503344.5000\n",
      "Epoch 740/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 488409.6875 - val_loss: 505745.2500\n",
      "Epoch 741/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 487963.7188 - val_loss: 507058.5000\n",
      "Epoch 742/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 488347.5625 - val_loss: 508008.4375\n",
      "Epoch 743/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 487130.2500 - val_loss: 504993.1875\n",
      "Epoch 744/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 486424.8750 - val_loss: 502096.3750\n",
      "Epoch 745/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 486541.0938 - val_loss: 502386.4375\n",
      "Epoch 746/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 485822.5312 - val_loss: 502587.0938\n",
      "Epoch 747/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 485583.5000 - val_loss: 502637.3750\n",
      "Epoch 748/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 484670.0938 - val_loss: 503693.0000\n",
      "Epoch 749/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 484510.1875 - val_loss: 505416.0000\n",
      "Epoch 750/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 483973.8125 - val_loss: 505304.9375\n",
      "Epoch 751/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 483767.9375 - val_loss: 504131.9062\n",
      "Epoch 752/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 483834.5625 - val_loss: 503896.3750\n",
      "Epoch 753/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 482648.8125 - val_loss: 501980.9375\n",
      "Epoch 754/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 482089.0312 - val_loss: 501107.2188\n",
      "Epoch 755/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 482264.8125 - val_loss: 500225.0938\n",
      "Epoch 756/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 481192.5938 - val_loss: 502171.9688\n",
      "Epoch 757/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 481431.8750 - val_loss: 501959.9062\n",
      "Epoch 758/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 480453.9688 - val_loss: 503252.9062\n",
      "Epoch 759/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 480663.4375 - val_loss: 504253.2812\n",
      "Epoch 760/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 479723.7188 - val_loss: 501314.8438\n",
      "Epoch 761/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 479566.4688 - val_loss: 498841.6250\n",
      "Epoch 762/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 478817.6875 - val_loss: 499588.0938\n",
      "Epoch 763/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 479113.8125 - val_loss: 500696.5312\n",
      "Epoch 764/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 478592.3438 - val_loss: 498037.0000\n",
      "Epoch 765/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 477920.8125 - val_loss: 499384.5000\n",
      "Epoch 766/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 477697.2188 - val_loss: 496463.6875\n",
      "Epoch 767/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 477293.5938 - val_loss: 495689.9688\n",
      "Epoch 768/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 476785.1562 - val_loss: 497488.3125\n",
      "Epoch 769/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 476443.0625 - val_loss: 495802.5625\n",
      "Epoch 770/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 476251.0625 - val_loss: 498510.2188\n",
      "Epoch 771/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 475394.5312 - val_loss: 497725.4375\n",
      "Epoch 772/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 475235.8438 - val_loss: 495723.1562\n",
      "Epoch 773/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 475075.0625 - val_loss: 496319.0625\n",
      "Epoch 774/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 474125.3750 - val_loss: 494680.2188\n",
      "Epoch 775/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 474468.1562 - val_loss: 493621.5938\n",
      "Epoch 776/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 473961.2500 - val_loss: 494184.5000\n",
      "Epoch 777/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 31ms/step - loss: 473127.4375 - val_loss: 494092.9062\n",
      "Epoch 778/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 473027.2812 - val_loss: 493631.3438\n",
      "Epoch 779/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 472797.5938 - val_loss: 493125.2188\n",
      "Epoch 780/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 472275.5625 - val_loss: 493779.0938\n",
      "Epoch 781/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 471459.1875 - val_loss: 494824.1562\n",
      "Epoch 782/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 471141.8750 - val_loss: 492194.4062\n",
      "Epoch 783/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 471107.8750 - val_loss: 490047.1875\n",
      "Epoch 784/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 470661.3125 - val_loss: 492415.1250\n",
      "Epoch 785/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 470364.7812 - val_loss: 492200.3125\n",
      "Epoch 786/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 469718.9062 - val_loss: 489947.7500\n",
      "Epoch 787/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 469469.7500 - val_loss: 491450.4062\n",
      "Epoch 788/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 469752.0000 - val_loss: 488802.5625\n",
      "Epoch 789/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 469787.4375 - val_loss: 493652.9062\n",
      "Epoch 790/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 469353.1562 - val_loss: 488308.3438\n",
      "Epoch 791/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 467960.8750 - val_loss: 490756.0312\n",
      "Epoch 792/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 467289.2188 - val_loss: 488584.9375\n",
      "Epoch 793/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 467088.9375 - val_loss: 488419.7500\n",
      "Epoch 794/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 466554.0938 - val_loss: 488785.0312\n",
      "Epoch 795/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 466584.2812 - val_loss: 486724.1250\n",
      "Epoch 796/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 465949.4688 - val_loss: 487329.4688\n",
      "Epoch 797/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 465328.6562 - val_loss: 489526.5938\n",
      "Epoch 798/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 465197.2500 - val_loss: 490218.0000\n",
      "Epoch 799/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 464916.1562 - val_loss: 489677.3750\n",
      "Epoch 800/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 465181.8125 - val_loss: 485542.3125\n",
      "Epoch 801/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 465063.4375 - val_loss: 486863.7812\n",
      "Epoch 802/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 463643.3438 - val_loss: 486323.4375\n",
      "Epoch 803/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 463380.5938 - val_loss: 487922.5000\n",
      "Epoch 804/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 463362.6875 - val_loss: 488737.7500\n",
      "Epoch 805/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 462758.5312 - val_loss: 485862.9688\n",
      "Epoch 806/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 462231.8750 - val_loss: 485380.7500\n",
      "Epoch 807/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 462206.3125 - val_loss: 484933.6562\n",
      "Epoch 808/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 462604.4375 - val_loss: 482004.8438\n",
      "Epoch 809/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 461695.2812 - val_loss: 486463.1250\n",
      "Epoch 810/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 461055.0625 - val_loss: 484944.2812\n",
      "Epoch 811/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 460814.3438 - val_loss: 483612.9062\n",
      "Epoch 812/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 460823.9375 - val_loss: 484957.9375\n",
      "Epoch 813/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 459919.2812 - val_loss: 482513.9688\n",
      "Epoch 814/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 459384.2812 - val_loss: 485383.2812\n",
      "Epoch 815/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 459455.0625 - val_loss: 485888.8750\n",
      "Epoch 816/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 458932.9062 - val_loss: 483687.4688\n",
      "Epoch 817/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 458625.4375 - val_loss: 481893.3438\n",
      "Epoch 818/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 458296.4375 - val_loss: 482156.6250\n",
      "Epoch 819/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 458043.5625 - val_loss: 483741.2188\n",
      "Epoch 820/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 457721.8750 - val_loss: 482827.5938\n",
      "Epoch 821/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 457517.3750 - val_loss: 482865.6250\n",
      "Epoch 822/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 456690.9688 - val_loss: 480863.6250\n",
      "Epoch 823/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 457325.3125 - val_loss: 482613.0625\n",
      "Epoch 824/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 456041.9688 - val_loss: 479973.0000\n",
      "Epoch 825/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 455809.1875 - val_loss: 480232.9375\n",
      "Epoch 826/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 455828.3750 - val_loss: 480603.8125\n",
      "Epoch 827/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 455775.5625 - val_loss: 482285.0625\n",
      "Epoch 828/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 454991.6250 - val_loss: 479985.9688\n",
      "Epoch 829/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 454732.3438 - val_loss: 479635.5938\n",
      "Epoch 830/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 454356.5625 - val_loss: 479150.1562\n",
      "Epoch 831/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 454170.3438 - val_loss: 479539.1562\n",
      "Epoch 832/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 453731.6562 - val_loss: 480800.5938\n",
      "Epoch 833/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 453669.3125 - val_loss: 480608.3750\n",
      "Epoch 834/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 453240.4062 - val_loss: 481587.2500\n",
      "Epoch 835/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 453247.3750 - val_loss: 480696.7188\n",
      "Epoch 836/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 452475.8750 - val_loss: 481650.2188\n",
      "Epoch 837/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 452456.5938 - val_loss: 482439.2500\n",
      "Epoch 838/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 452102.9375 - val_loss: 481467.2500\n",
      "Epoch 839/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 451284.9688 - val_loss: 476599.2500\n",
      "Epoch 840/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 451582.3438 - val_loss: 476934.6250\n",
      "Epoch 841/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 451123.4375 - val_loss: 476626.0625\n",
      "Epoch 842/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 451119.6250 - val_loss: 479831.0625\n",
      "Epoch 843/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 450449.9062 - val_loss: 477901.1250\n",
      "Epoch 844/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 450232.5625 - val_loss: 479137.7500\n",
      "Epoch 845/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 449720.0312 - val_loss: 478736.5000\n",
      "Epoch 846/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 449925.2812 - val_loss: 477188.1250\n",
      "Epoch 847/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 449530.6250 - val_loss: 479452.7812\n",
      "Epoch 848/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 448643.5625 - val_loss: 477121.1875\n",
      "Epoch 849/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 31ms/step - loss: 448882.0625 - val_loss: 474328.5000\n",
      "Epoch 850/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 448300.1250 - val_loss: 475545.4062\n",
      "Epoch 851/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 447907.6875 - val_loss: 476172.6875\n",
      "Epoch 852/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 447722.9375 - val_loss: 474006.9688\n",
      "Epoch 853/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 447637.4375 - val_loss: 475100.5625\n",
      "Epoch 854/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 447060.0000 - val_loss: 475631.7188\n",
      "Epoch 855/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 446646.0000 - val_loss: 475254.0938\n",
      "Epoch 856/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 446172.9375 - val_loss: 475742.5938\n",
      "Epoch 857/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 445946.2500 - val_loss: 474826.8750\n",
      "Epoch 858/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 446133.9062 - val_loss: 475445.7188\n",
      "Epoch 859/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 445584.9688 - val_loss: 473842.4062\n",
      "Epoch 860/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 445098.6250 - val_loss: 473419.7500\n",
      "Epoch 861/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 444990.8125 - val_loss: 472422.2188\n",
      "Epoch 862/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 444582.5625 - val_loss: 473990.9688\n",
      "Epoch 863/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 445787.5312 - val_loss: 472281.9688\n",
      "Epoch 864/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 444070.8438 - val_loss: 474365.1562\n",
      "Epoch 865/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 443681.4062 - val_loss: 474643.3125\n",
      "Epoch 866/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 443623.6875 - val_loss: 470848.1562\n",
      "Epoch 867/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 443059.9375 - val_loss: 473366.5938\n",
      "Epoch 868/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 442530.1562 - val_loss: 473324.3125\n",
      "Epoch 869/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 442693.3125 - val_loss: 472534.3125\n",
      "Epoch 870/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 442399.9062 - val_loss: 471073.0938\n",
      "Epoch 871/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 441776.9688 - val_loss: 473335.6250\n",
      "Epoch 872/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 441595.2812 - val_loss: 473668.2500\n",
      "Epoch 873/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 441379.4375 - val_loss: 474028.4062\n",
      "Epoch 874/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 441680.0938 - val_loss: 473583.4688\n",
      "Epoch 875/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 441317.7812 - val_loss: 473541.5625\n",
      "Epoch 876/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 440325.9375 - val_loss: 471466.8438\n",
      "Epoch 877/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 440324.2500 - val_loss: 468825.7812\n",
      "Epoch 878/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 439720.0312 - val_loss: 470520.7500\n",
      "Epoch 879/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 439613.9375 - val_loss: 470864.1562\n",
      "Epoch 880/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 438979.4375 - val_loss: 469022.2500\n",
      "Epoch 881/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 439603.0000 - val_loss: 466650.8438\n",
      "Epoch 882/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 438744.3750 - val_loss: 469178.2188\n",
      "Epoch 883/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 438383.2500 - val_loss: 468249.6875\n",
      "Epoch 884/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 438238.0625 - val_loss: 467527.5625\n",
      "Epoch 885/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 438044.0938 - val_loss: 467789.1250\n",
      "Epoch 886/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 437324.0000 - val_loss: 468153.5312\n",
      "Epoch 887/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 437044.1250 - val_loss: 469687.9375\n",
      "Epoch 888/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 437279.1875 - val_loss: 471059.1562\n",
      "Epoch 889/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 437004.3750 - val_loss: 469104.7188\n",
      "Epoch 890/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 437226.5938 - val_loss: 465878.3125\n",
      "Epoch 891/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 435899.3438 - val_loss: 467907.2500\n",
      "Epoch 892/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 435361.2188 - val_loss: 469149.6562\n",
      "Epoch 893/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 435276.8438 - val_loss: 469353.5312\n",
      "Epoch 894/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 434898.5625 - val_loss: 468579.8750\n",
      "Epoch 895/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 434626.1250 - val_loss: 467050.4062\n",
      "Epoch 896/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 434365.7500 - val_loss: 469182.6875\n",
      "Epoch 897/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 434233.4375 - val_loss: 468104.2188\n",
      "Epoch 898/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 433384.3750 - val_loss: 467136.5312\n",
      "Epoch 899/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 433554.5625 - val_loss: 467317.5625\n",
      "Epoch 900/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 433126.7812 - val_loss: 468557.3750\n",
      "Epoch 901/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 432690.3438 - val_loss: 468321.3750\n",
      "Epoch 902/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 432524.4062 - val_loss: 468926.0312\n",
      "Epoch 903/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 432054.6875 - val_loss: 468040.8750\n",
      "Epoch 904/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 432498.3438 - val_loss: 465771.0625\n",
      "Epoch 905/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 431731.0938 - val_loss: 467547.3750\n",
      "Epoch 906/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 431277.9688 - val_loss: 466737.7812\n",
      "Epoch 907/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 431340.6875 - val_loss: 465802.3438\n",
      "Epoch 908/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 430721.0000 - val_loss: 466738.7188\n",
      "Epoch 909/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 430423.4062 - val_loss: 465929.6250\n",
      "Epoch 910/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 430074.3438 - val_loss: 465314.5625\n",
      "Epoch 911/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 430044.6562 - val_loss: 465919.3438\n",
      "Epoch 912/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 429277.9062 - val_loss: 466903.8438\n",
      "Epoch 913/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 429144.0312 - val_loss: 466595.5938\n",
      "Epoch 914/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 429032.1250 - val_loss: 467359.1250\n",
      "Epoch 915/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 428370.9375 - val_loss: 466393.8438\n",
      "Epoch 916/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 428010.4062 - val_loss: 464750.9062\n",
      "Epoch 917/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 427811.1562 - val_loss: 464140.4688\n",
      "Epoch 918/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 427472.3438 - val_loss: 466265.7500\n",
      "Epoch 919/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 427420.0625 - val_loss: 465357.0000\n",
      "Epoch 920/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 427402.2812 - val_loss: 464674.4062\n",
      "Epoch 921/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 31ms/step - loss: 426745.0312 - val_loss: 463929.0312\n",
      "Epoch 922/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 426466.6875 - val_loss: 463562.2812\n",
      "Epoch 923/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 426609.0938 - val_loss: 462644.9062\n",
      "Epoch 924/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 425728.6250 - val_loss: 461505.2500\n",
      "Epoch 925/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 426097.4062 - val_loss: 462033.5938\n",
      "Epoch 926/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 425117.0312 - val_loss: 464775.1250\n",
      "Epoch 927/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 424987.2812 - val_loss: 465863.2812\n",
      "Epoch 928/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 424730.5938 - val_loss: 463325.1562\n",
      "Epoch 929/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 424495.9062 - val_loss: 462238.0000\n",
      "Epoch 930/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 424158.5000 - val_loss: 464123.0938\n",
      "Epoch 931/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 424060.1250 - val_loss: 462600.3125\n",
      "Epoch 932/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 423396.3438 - val_loss: 462842.2188\n",
      "Epoch 933/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 422912.9062 - val_loss: 462992.0000\n",
      "Epoch 934/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 422615.0000 - val_loss: 462637.7188\n",
      "Epoch 935/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 422635.3125 - val_loss: 463261.8750\n",
      "Epoch 936/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 422038.7188 - val_loss: 461918.6250\n",
      "Epoch 937/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 421842.8438 - val_loss: 461670.8125\n",
      "Epoch 938/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 421490.2188 - val_loss: 460323.5938\n",
      "Epoch 939/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 421792.5312 - val_loss: 462167.0625\n",
      "Epoch 940/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 421066.8438 - val_loss: 460853.8750\n",
      "Epoch 941/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 420535.9688 - val_loss: 460788.7500\n",
      "Epoch 942/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 420499.6562 - val_loss: 461964.4062\n",
      "Epoch 943/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 419903.7812 - val_loss: 461553.1562\n",
      "Epoch 944/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 419408.7812 - val_loss: 462030.6875\n",
      "Epoch 945/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 419718.7188 - val_loss: 460888.0625\n",
      "Epoch 946/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 418997.2500 - val_loss: 461110.5312\n",
      "Epoch 947/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 418527.8750 - val_loss: 460786.4375\n",
      "Epoch 948/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 419056.0000 - val_loss: 460187.4375\n",
      "Epoch 949/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 418559.5625 - val_loss: 461714.6562\n",
      "Epoch 950/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 417680.8750 - val_loss: 459003.0625\n",
      "Epoch 951/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 417882.4062 - val_loss: 459736.9375\n",
      "Epoch 952/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 418330.9688 - val_loss: 455932.0938\n",
      "Epoch 953/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 416942.1562 - val_loss: 459600.0625\n",
      "Epoch 954/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 416624.3125 - val_loss: 460826.6562\n",
      "Epoch 955/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 416215.4062 - val_loss: 461109.2188\n",
      "Epoch 956/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 416292.9375 - val_loss: 459990.5312\n",
      "Epoch 957/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 415651.0625 - val_loss: 458236.8438\n",
      "Epoch 958/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 415222.7812 - val_loss: 458288.4375\n",
      "Epoch 959/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 417141.6875 - val_loss: 456037.8125\n",
      "Epoch 960/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 415215.7812 - val_loss: 457155.9062\n",
      "Epoch 961/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 414549.5625 - val_loss: 458381.8125\n",
      "Epoch 962/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 413897.8750 - val_loss: 458241.3750\n",
      "Epoch 963/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 413834.9375 - val_loss: 459025.1562\n",
      "Epoch 964/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 413461.8438 - val_loss: 456917.8125\n",
      "Epoch 965/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 412905.2188 - val_loss: 457204.1250\n",
      "Epoch 966/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 412853.0625 - val_loss: 456454.3438\n",
      "Epoch 967/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 412366.0625 - val_loss: 456598.2188\n",
      "Epoch 968/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 412196.6250 - val_loss: 456515.5312\n",
      "Epoch 969/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 412141.1562 - val_loss: 459868.9375\n",
      "Epoch 970/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 411513.1562 - val_loss: 456388.5938\n",
      "Epoch 971/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 411193.2188 - val_loss: 456279.1250\n",
      "Epoch 972/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 410855.2188 - val_loss: 456063.6875\n",
      "Epoch 973/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 410892.4375 - val_loss: 456532.9062\n",
      "Epoch 974/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 410151.7188 - val_loss: 455929.6875\n",
      "Epoch 975/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 410024.0625 - val_loss: 455489.3438\n",
      "Epoch 976/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 409744.6250 - val_loss: 455173.9375\n",
      "Epoch 977/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 409326.3438 - val_loss: 454859.2500\n",
      "Epoch 978/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 409008.7812 - val_loss: 455986.1875\n",
      "Epoch 979/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 409100.3438 - val_loss: 455073.2188\n",
      "Epoch 980/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 408988.3438 - val_loss: 456295.0625\n",
      "Epoch 981/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 408246.5938 - val_loss: 455092.0312\n",
      "Epoch 982/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 408284.3125 - val_loss: 455890.7812\n",
      "Epoch 983/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 407839.9062 - val_loss: 454062.0000\n",
      "Epoch 984/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 407515.0312 - val_loss: 453262.4375\n",
      "Epoch 985/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 407512.2500 - val_loss: 453272.1562\n",
      "Epoch 986/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 407592.9688 - val_loss: 455975.5625\n",
      "Epoch 987/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 407216.9062 - val_loss: 455176.5312\n",
      "Epoch 988/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 406124.7812 - val_loss: 456471.1875\n",
      "Epoch 989/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 405776.0312 - val_loss: 455032.6875\n",
      "Epoch 990/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 405618.7188 - val_loss: 454893.3750\n",
      "Epoch 991/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 405406.9375 - val_loss: 454936.3125\n",
      "Epoch 992/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 404874.9062 - val_loss: 452960.4062\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 32ms/step - loss: 404940.1250 - val_loss: 452287.5000\n",
      "Epoch 994/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 404542.0938 - val_loss: 455114.1250\n",
      "Epoch 995/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 404463.2500 - val_loss: 455106.5938\n",
      "Epoch 996/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 404038.9375 - val_loss: 454522.7188\n",
      "Epoch 997/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 403716.7812 - val_loss: 450871.0312\n",
      "Epoch 998/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 403587.4062 - val_loss: 451376.5938\n",
      "Epoch 999/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 402942.9688 - val_loss: 452414.5625\n",
      "Epoch 1000/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 402607.1250 - val_loss: 452516.4062\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 452516.4062\n",
      "Mean Squared Error on Test Data: 452516.40625\n",
      "5/5 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "day_Bike = pd.read_csv(r'C:\\Users\\jackf\\OneDrive\\Desktop\\Bike_Sharing\\UCI_Bike_Sharing\\data\\day.csv')  \n",
    "features = day_Bike[['season', 'yr', 'mnth', 'holiday',\n",
    "                     'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed']]\n",
    "target = day_Bike['cnt']\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target.values, test_size=0.2, random_state=42)\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "model = Sequential()\n",
    "model.add(LSTM(1000, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X_train, y_train, epochs= 1000, batch_size=32, validation_data=(X_test, y_test))\n",
    "mse = model.evaluate(X_test, y_test)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96b90e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.8871497051320987\n"
     ]
    }
   ],
   "source": [
    "r_squared = r2_score(y_test, predictions)\n",
    "print(f'R-squared: {r_squared}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b20b0a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e57b8aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/19 [==============================] - 1s 12ms/step - loss: 24467272.0000 - val_loss: 22320674.0000\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24464028.0000 - val_loss: 22316782.0000\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24458676.0000 - val_loss: 22310096.0000\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24449562.0000 - val_loss: 22299156.0000\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24434920.0000 - val_loss: 22282288.0000\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24413180.0000 - val_loss: 22257834.0000\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24383082.0000 - val_loss: 22225016.0000\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24342652.0000 - val_loss: 22182472.0000\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24293086.0000 - val_loss: 22130856.0000\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24233438.0000 - val_loss: 22069804.0000\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24162714.0000 - val_loss: 21999196.0000\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24082364.0000 - val_loss: 21920074.0000\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23993206.0000 - val_loss: 21833682.0000\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23898232.0000 - val_loss: 21738878.0000\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23790602.0000 - val_loss: 21637140.0000\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23676688.0000 - val_loss: 21529892.0000\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23563962.0000 - val_loss: 21415070.0000\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23431990.0000 - val_loss: 21295750.0000\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23301314.0000 - val_loss: 21169050.0000\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23169010.0000 - val_loss: 21039648.0000\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23025930.0000 - val_loss: 20904838.0000\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22874754.0000 - val_loss: 20765862.0000\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22724300.0000 - val_loss: 20620992.0000\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22581600.0000 - val_loss: 20474688.0000\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22410464.0000 - val_loss: 20325082.0000\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22257780.0000 - val_loss: 20170282.0000\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22067912.0000 - val_loss: 20012338.0000\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21903078.0000 - val_loss: 19849342.0000\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21726964.0000 - val_loss: 19683460.0000\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21555454.0000 - val_loss: 19515354.0000\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21360584.0000 - val_loss: 19343140.0000\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21177118.0000 - val_loss: 19169032.0000\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20974904.0000 - val_loss: 18991932.0000\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20768258.0000 - val_loss: 18809108.0000\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20598548.0000 - val_loss: 18628106.0000\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20401992.0000 - val_loss: 18445224.0000\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20178300.0000 - val_loss: 18255152.0000\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20027896.0000 - val_loss: 18068524.0000\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19779250.0000 - val_loss: 17875610.0000\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19587374.0000 - val_loss: 17678484.0000\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19361436.0000 - val_loss: 17482228.0000\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19181704.0000 - val_loss: 17281358.0000\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18918578.0000 - val_loss: 17079192.0000\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18708200.0000 - val_loss: 16874348.0000\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18512658.0000 - val_loss: 16670027.0000\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18282620.0000 - val_loss: 16465394.0000\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18063742.0000 - val_loss: 16260354.0000\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17834588.0000 - val_loss: 16051952.0000\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17588492.0000 - val_loss: 15842703.0000\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17360702.0000 - val_loss: 15633904.0000\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17179876.0000 - val_loss: 15424070.0000\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16955612.0000 - val_loss: 15215888.0000\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16695415.0000 - val_loss: 15006523.0000\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16461465.0000 - val_loss: 14796605.0000\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16268649.0000 - val_loss: 14587288.0000\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16015854.0000 - val_loss: 14377944.0000\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15854399.0000 - val_loss: 14168377.0000\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15561398.0000 - val_loss: 13960505.0000\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15330376.0000 - val_loss: 13749184.0000\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15071977.0000 - val_loss: 13534777.0000\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14930756.0000 - val_loss: 13323118.0000\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14650428.0000 - val_loss: 13111310.0000\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14419168.0000 - val_loss: 12897754.0000\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14196528.0000 - val_loss: 12686609.0000\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13992337.0000 - val_loss: 12475477.0000\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13741566.0000 - val_loss: 12266752.0000\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13456494.0000 - val_loss: 12052072.0000\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13271389.0000 - val_loss: 11843543.0000\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13038683.0000 - val_loss: 11639315.0000\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12806566.0000 - val_loss: 11434119.0000\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12571407.0000 - val_loss: 11227216.0000\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12363137.0000 - val_loss: 11026521.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12171372.0000 - val_loss: 10829826.0000\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11915284.0000 - val_loss: 10630779.0000\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11701490.0000 - val_loss: 10432488.0000\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11459537.0000 - val_loss: 10238959.0000\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11219359.0000 - val_loss: 10044369.0000\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11060786.0000 - val_loss: 9852251.0000\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 10873525.0000 - val_loss: 9663016.0000\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 10641802.0000 - val_loss: 9475124.0000\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 10439655.0000 - val_loss: 9293956.0000\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 10276775.0000 - val_loss: 9112184.0000\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 10043309.0000 - val_loss: 8929961.0000\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 9859275.0000 - val_loss: 8750366.0000\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 9641743.0000 - val_loss: 8570515.0000\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 9446298.0000 - val_loss: 8396651.0000\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 9346790.0000 - val_loss: 8221084.5000\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 9107948.0000 - val_loss: 8052395.5000\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 8855674.0000 - val_loss: 7882296.5000\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 8716846.0000 - val_loss: 7719194.0000\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 8482482.0000 - val_loss: 7556802.0000\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 8270095.0000 - val_loss: 7400468.0000\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 8214748.0000 - val_loss: 7245424.5000\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 7985888.5000 - val_loss: 7093150.0000\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 7865431.0000 - val_loss: 6946357.5000\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 7643768.0000 - val_loss: 6796916.5000\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 7518387.5000 - val_loss: 6654395.0000\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 7337932.5000 - val_loss: 6512359.5000\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 7136800.5000 - val_loss: 6375066.5000\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 7042861.0000 - val_loss: 6243223.0000\n",
      "5/5 [==============================] - 0s 999us/step - loss: 6243223.0000\n",
      "Mean Squared Error on Test Data: 6243223.0\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[3155.7095 1690.8014 2879.4338 2111.0427 3104.4258 3058.3638 1714.1097\n",
      " 2477.3508 3282.737  2933.7249 1959.9944 2486.67   2337.0227 2922.6858\n",
      " 1565.1835 1111.4144 1577.7719 3319.7544 2631.4602 1681.5844 3001.8677\n",
      " 3248.0754 2600.0886 1699.5477 2103.75   2715.1619 2318.8801 2875.4702\n",
      " 2194.9343 3099.339  1700.2828 3168.2678 2451.0508 2817.4402 2463.3606\n",
      " 2686.265  3343.0525 3150.2695 3068.388  1674.5947 2332.6782 2043.7404\n",
      " 3117.151  1953.84   2969.1033 3298.6575 2604.1182 2222.6921 2580.112\n",
      " 2223.535  2658.7139 1842.6971 1903.8856 2457.0588 2641.7405 3011.092\n",
      " 3141.5662 1729.359  1869.4846 3557.3833 2372.283  2929.954  2477.2488\n",
      " 2859.3362 3101.1584 2901.848  2896.119  2037.8328 2001.8081 2300.424\n",
      " 1824.3066 1740.2773 2706.949  2319.0251 2081.8242 2450.273  2833.3914\n",
      " 2837.9285 1254.0795 2510.6338 2928.153  1627.0709 3012.3877 3583.8013\n",
      " 2666.218  1906.714  2766.6213 2445.4128 2660.7979 2404.632  1626.9298\n",
      " 3070.5037 3153.1526 2526.2566 2815.4678 2146.586  2475.601  2039.5209\n",
      " 2321.5906 2778.8718 3078.9443 2187.721  2967.6926 1597.1581 2266.3523\n",
      " 3038.8887 2363.7085 2530.2239 3311.1233 1754.9337 2647.3381 3216.051\n",
      " 2616.9592 3186.6062 2807.013  2548.9934 2338.0144 2091.9583 2430.42\n",
      " 2367.341  2575.365  3183.0667 2192.5674 1414.4316 2625.388  2948.182\n",
      " 2639.8237 2536.6274 1855.0458 2585.8909 1874.6654 2714.987  2924.3577\n",
      " 3131.2495 2454.1152 2396.551  2735.382  2357.9036 2197.2278 2559.8013\n",
      " 2399.2866 1826.8097 1627.5256 2665.666  2694.161  2312.45   2188.1184]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "day_Bike = pd.read_csv(r'C:\\Users\\jackf\\OneDrive\\Desktop\\Bike_Sharing\\UCI_Bike_Sharing\\data\\day.csv')\n",
    "\n",
    "\n",
    "features = day_Bike[['season', 'yr', 'mnth', 'holiday',\n",
    "                     'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed']]\n",
    "\n",
    "\n",
    "target = day_Bike['cnt']\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target.values, test_size=0.2, random_state=42)\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), activation='relu'))\n",
    "model.add(Dropout(0.2))  \n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "mse = model.evaluate(X_test, y_test)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "predictions = model.predict(X_test)\n",
    "predicted_values = np.squeeze(predictions)\n",
    "print(predicted_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddb4d34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>727</td>\n",
       "      <td>2012-12-27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>0.226642</td>\n",
       "      <td>0.652917</td>\n",
       "      <td>0.350133</td>\n",
       "      <td>247</td>\n",
       "      <td>1867</td>\n",
       "      <td>2114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>728</td>\n",
       "      <td>2012-12-28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.255046</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.155471</td>\n",
       "      <td>644</td>\n",
       "      <td>2451</td>\n",
       "      <td>3095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>729</td>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.242400</td>\n",
       "      <td>0.752917</td>\n",
       "      <td>0.124383</td>\n",
       "      <td>159</td>\n",
       "      <td>1182</td>\n",
       "      <td>1341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>730</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255833</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.350754</td>\n",
       "      <td>364</td>\n",
       "      <td>1432</td>\n",
       "      <td>1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>731</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.215833</td>\n",
       "      <td>0.223487</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.154846</td>\n",
       "      <td>439</td>\n",
       "      <td>2290</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>731 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "0          1  2011-01-01       1   0     1        0        6           0   \n",
       "1          2  2011-01-02       1   0     1        0        0           0   \n",
       "2          3  2011-01-03       1   0     1        0        1           1   \n",
       "3          4  2011-01-04       1   0     1        0        2           1   \n",
       "4          5  2011-01-05       1   0     1        0        3           1   \n",
       "..       ...         ...     ...  ..   ...      ...      ...         ...   \n",
       "726      727  2012-12-27       1   1    12        0        4           1   \n",
       "727      728  2012-12-28       1   1    12        0        5           1   \n",
       "728      729  2012-12-29       1   1    12        0        6           0   \n",
       "729      730  2012-12-30       1   1    12        0        0           0   \n",
       "730      731  2012-12-31       1   1    12        0        1           1   \n",
       "\n",
       "     weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
       "0             2  0.344167  0.363625  0.805833   0.160446     331         654   \n",
       "1             2  0.363478  0.353739  0.696087   0.248539     131         670   \n",
       "2             1  0.196364  0.189405  0.437273   0.248309     120        1229   \n",
       "3             1  0.200000  0.212122  0.590435   0.160296     108        1454   \n",
       "4             1  0.226957  0.229270  0.436957   0.186900      82        1518   \n",
       "..          ...       ...       ...       ...        ...     ...         ...   \n",
       "726           2  0.254167  0.226642  0.652917   0.350133     247        1867   \n",
       "727           2  0.253333  0.255046  0.590000   0.155471     644        2451   \n",
       "728           2  0.253333  0.242400  0.752917   0.124383     159        1182   \n",
       "729           1  0.255833  0.231700  0.483333   0.350754     364        1432   \n",
       "730           2  0.215833  0.223487  0.577500   0.154846     439        2290   \n",
       "\n",
       "      cnt  \n",
       "0     985  \n",
       "1     801  \n",
       "2    1349  \n",
       "3    1562  \n",
       "4    1600  \n",
       "..    ...  \n",
       "726  2114  \n",
       "727  3095  \n",
       "728  1341  \n",
       "729  1796  \n",
       "730  2729  \n",
       "\n",
       "[731 rows x 16 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_Bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f08938e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "2296.1843\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_data = pd.DataFrame({\n",
    "    'season': [1], 'yr': [1], 'mnth': [12], 'holiday': [0], 'weekday': [1],\n",
    "    'workingday': [1], 'weathersit': [1], 'temp': [0.215833], 'atemp': [0.223487],\n",
    "    'hum': [0.577500], 'windspeed': [0.154846]\n",
    "})\n",
    "new_features_scaled = scaler.transform(new_data)\n",
    "new_predictions = model.predict(new_features_scaled)\n",
    "predicted_cnt_values = np.squeeze(new_predictions)\n",
    "print(predicted_cnt_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd75f92c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4812bdad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30884730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/19 [==============================] - 1s 12ms/step - loss: 24467762.0000 - val_loss: 22321810.0000\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24466298.0000 - val_loss: 22320080.0000\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24463940.0000 - val_loss: 22317108.0000\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24459982.0000 - val_loss: 22312194.0000\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24453668.0000 - val_loss: 22304768.0000\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24444448.0000 - val_loss: 22294196.0000\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24431560.0000 - val_loss: 22279902.0000\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24414742.0000 - val_loss: 22260786.0000\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24393080.0000 - val_loss: 22236746.0000\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24365146.0000 - val_loss: 22207652.0000\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24331534.0000 - val_loss: 22171618.0000\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24290974.0000 - val_loss: 22129848.0000\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24245526.0000 - val_loss: 22082216.0000\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24190850.0000 - val_loss: 22026950.0000\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24131818.0000 - val_loss: 21965684.0000\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24067158.0000 - val_loss: 21900096.0000\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23994596.0000 - val_loss: 21828806.0000\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23915660.0000 - val_loss: 21750858.0000\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23833178.0000 - val_loss: 21667804.0000\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23741504.0000 - val_loss: 21579666.0000\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23648100.0000 - val_loss: 21487912.0000\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23547962.0000 - val_loss: 21390866.0000\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23445568.0000 - val_loss: 21288758.0000\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23334982.0000 - val_loss: 21183282.0000\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23218420.0000 - val_loss: 21075016.0000\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23108100.0000 - val_loss: 20961912.0000\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22985244.0000 - val_loss: 20844698.0000\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22866680.0000 - val_loss: 20726874.0000\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22737980.0000 - val_loss: 20604486.0000\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22606200.0000 - val_loss: 20479380.0000\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22469972.0000 - val_loss: 20353138.0000\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22338300.0000 - val_loss: 20224090.0000\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22206620.0000 - val_loss: 20092032.0000\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22063278.0000 - val_loss: 19957604.0000\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21919094.0000 - val_loss: 19822834.0000\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21784748.0000 - val_loss: 19682512.0000\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21608444.0000 - val_loss: 19539340.0000\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21486800.0000 - val_loss: 19395726.0000\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21317648.0000 - val_loss: 19247272.0000\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21168642.0000 - val_loss: 19098600.0000\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21004688.0000 - val_loss: 18945642.0000\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20846212.0000 - val_loss: 18795876.0000\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20692660.0000 - val_loss: 18639914.0000\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20517084.0000 - val_loss: 18484516.0000\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20337970.0000 - val_loss: 18325550.0000\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20186602.0000 - val_loss: 18165672.0000\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20002794.0000 - val_loss: 18007892.0000\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19847876.0000 - val_loss: 17845386.0000\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19658546.0000 - val_loss: 17683156.0000\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19492434.0000 - val_loss: 17518686.0000\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19339070.0000 - val_loss: 17353712.0000\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19131618.0000 - val_loss: 17187140.0000\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18959432.0000 - val_loss: 17018328.0000\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18806698.0000 - val_loss: 16850586.0000\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18644744.0000 - val_loss: 16684851.0000\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18423506.0000 - val_loss: 16514772.0000\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18265992.0000 - val_loss: 16343562.0000\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18082122.0000 - val_loss: 16174047.0000\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17909308.0000 - val_loss: 16006370.0000\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17693888.0000 - val_loss: 15831747.0000\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17539586.0000 - val_loss: 15658736.0000\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17347174.0000 - val_loss: 15487944.0000\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17175104.0000 - val_loss: 15318821.0000\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16985134.0000 - val_loss: 15145554.0000\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16804806.0000 - val_loss: 14977451.0000\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16600180.0000 - val_loss: 14803480.0000\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16426633.0000 - val_loss: 14632225.0000\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16223374.0000 - val_loss: 14459040.0000\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16074633.0000 - val_loss: 14287891.0000\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15850831.0000 - val_loss: 14116677.0000\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15696382.0000 - val_loss: 13946032.0000\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15501505.0000 - val_loss: 13775367.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15334984.0000 - val_loss: 13603713.0000\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15119979.0000 - val_loss: 13432336.0000\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14988155.0000 - val_loss: 13262702.0000\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14780712.0000 - val_loss: 13094179.0000\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14558063.0000 - val_loss: 12921453.0000\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14431348.0000 - val_loss: 12751699.0000\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14198552.0000 - val_loss: 12583598.0000\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14051325.0000 - val_loss: 12415134.0000\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13870531.0000 - val_loss: 12250749.0000\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13696363.0000 - val_loss: 12084685.0000\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13528270.0000 - val_loss: 11918743.0000\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13355381.0000 - val_loss: 11753503.0000\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13160884.0000 - val_loss: 11590165.0000\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13030467.0000 - val_loss: 11430161.0000\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12766012.0000 - val_loss: 11270835.0000\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12617867.0000 - val_loss: 11109069.0000\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12427428.0000 - val_loss: 10948233.0000\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12342532.0000 - val_loss: 10790493.0000\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12145992.0000 - val_loss: 10632492.0000\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11901229.0000 - val_loss: 10475631.0000\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11706379.0000 - val_loss: 10318646.0000\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11587500.0000 - val_loss: 10165716.0000\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11404445.0000 - val_loss: 10011514.0000\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11306806.0000 - val_loss: 9859839.0000\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11050194.0000 - val_loss: 9710525.0000\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 10918139.0000 - val_loss: 9562058.0000\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 10815537.0000 - val_loss: 9415678.0000\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 10592353.0000 - val_loss: 9270047.0000\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9270047.0000\n",
      "Mean Squared Error on Test Data: 9270047.0\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "[2472.526   1557.8198  2082.3462  1273.6891  2315.1904  2305.0886\n",
      " 1459.0009  2187.7341  2494.75    2104.6416  1712.0148  2092.5332\n",
      " 1579.466   2514.8533  1414.8087   580.5741  1314.4698  2651.7954\n",
      " 1923.5465  1553.3903  2357.593   2442.342   2242.4     1314.4698\n",
      " 1557.8198  1784.4352  1514.0143  2220.191   2137.0305  2472.526\n",
      " 1117.0934  2082.3462  2147.2153  2347.5024  2051.8018  1809.7922\n",
      " 2547.125   2075.2075  1944.1423  1302.9447  1568.6667  1998.8549\n",
      " 2357.593    763.4603  2114.8337  1997.1014  1535.8116  1902.9387\n",
      " 1768.6747  1217.0286  1400.3058  1117.0934  1711.9784  1440.8241\n",
      " 1687.6425  2029.5228  2029.5228   702.69305  702.69305 2547.125\n",
      " 1902.9387  2157.3882  1763.4786  2075.2075  2167.5503  2252.5303\n",
      " 2066.2576   823.8089  1217.2788  1550.1246  1217.2788  1160.109\n",
      " 1805.2833  1763.4788  1945.7833  1470.0673  2420.1204  1794.872\n",
      " 1200.9348  1677.049   2661.8223  1314.4698  2704.0984  2272.766\n",
      " 2187.7341  1809.7922  1550.1492  1799.768   2187.7341  1805.2833\n",
      " 1200.9348  2262.6523  2704.0984  2189.7534  2756.3838  1756.236\n",
      " 1644.3387  1988.5695  1329.9861  1870.3588  2452.4082   883.64014\n",
      " 2062.0293  1217.2788  1314.4698  2567.2083  1901.3766  1711.9784\n",
      " 2399.9763  1359.1173  1687.6425  2651.7954  1698.202   2599.4722\n",
      " 2094.4363  1550.1492  1655.7518  2084.2178  1440.8241  1988.5695\n",
      " 2337.4055  1944.1423  1709.7358  1200.9348  1751.8408  2514.8533\n",
      " 1633.6885  1895.638   1514.0143  1440.7424  1001.55615 2039.7444\n",
      " 2514.8533  2567.2083  1687.6425  1763.4788  2147.2153  1863.1613\n",
      " 1709.7358  1590.2203  1720.31    1257.9811  1217.2788  1633.6885\n",
      " 2135.079   1677.049   1425.9691 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "day_Bike = pd.read_csv(r'C:\\Users\\jackf\\OneDrive\\Desktop\\Bike_Sharing\\UCI_Bike_Sharing\\data\\day.csv')\n",
    "features = day_Bike[['yr', 'mnth', \n",
    "                     'holiday', 'weekday', 'workingday' ]]\n",
    "\n",
    "\n",
    "target = day_Bike['cnt']\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target.values, test_size=0.2, random_state=42)\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), activation='relu'))\n",
    "model.add(Dropout(0.2))  \n",
    "model.add(Dense(1))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "mse = model.evaluate(X_test, y_test)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "predictions = model.predict(X_test)\n",
    "predicted_values = np.squeeze(predictions)\n",
    "print(predicted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f114bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "2377.7556\n"
     ]
    }
   ],
   "source": [
    "# Replace 'new_data' with your actual new data\n",
    "new_data = pd.DataFrame({\n",
    "     'yr': [1], 'mnth': [12], 'holiday': [0], 'weekday': [1],\n",
    "    'workingday': [1]\n",
    "     \n",
    "})\n",
    "\n",
    "new_features_scaled = scaler.transform(new_data)\n",
    "new_features_scaled = new_features_scaled.reshape((new_features_scaled.shape[0], 1, new_features_scaled.shape[1]))\n",
    "new_predictions = model.predict(new_features_scaled)\n",
    "predicted_cnt_values = np.squeeze(new_predictions)\n",
    "print(predicted_cnt_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff4d333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d171ca73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0b55796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/19 [==============================] - 1s 12ms/step - loss: 24467660.0000 - val_loss: 22321592.0000\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24465768.0000 - val_loss: 22319430.0000\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24462826.0000 - val_loss: 22315992.0000\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24458076.0000 - val_loss: 22310554.0000\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24450946.0000 - val_loss: 22302468.0000\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24440240.0000 - val_loss: 22290950.0000\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24425508.0000 - val_loss: 22275096.0000\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24405666.0000 - val_loss: 22254546.0000\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24380010.0000 - val_loss: 22228390.0000\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24348308.0000 - val_loss: 22196402.0000\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24310146.0000 - val_loss: 22158484.0000\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24263954.0000 - val_loss: 22113858.0000\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24213046.0000 - val_loss: 22062578.0000\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24152654.0000 - val_loss: 22006344.0000\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24085284.0000 - val_loss: 21943790.0000\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24018680.0000 - val_loss: 21875040.0000\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23936360.0000 - val_loss: 21800738.0000\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23856390.0000 - val_loss: 21722604.0000\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23765710.0000 - val_loss: 21640846.0000\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23677464.0000 - val_loss: 21554190.0000\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23574480.0000 - val_loss: 21461138.0000\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23477198.0000 - val_loss: 21366406.0000\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23373938.0000 - val_loss: 21267476.0000\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23255574.0000 - val_loss: 21164544.0000\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23145380.0000 - val_loss: 21059408.0000\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23026728.0000 - val_loss: 20949370.0000\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22904662.0000 - val_loss: 20837240.0000\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22771762.0000 - val_loss: 20721280.0000\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22650778.0000 - val_loss: 20604502.0000\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22527172.0000 - val_loss: 20482384.0000\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22393352.0000 - val_loss: 20359464.0000\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22259248.0000 - val_loss: 20232198.0000\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22114890.0000 - val_loss: 20103900.0000\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21963598.0000 - val_loss: 19969946.0000\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21819166.0000 - val_loss: 19834834.0000\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21678536.0000 - val_loss: 19697522.0000\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21514504.0000 - val_loss: 19557508.0000\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21370196.0000 - val_loss: 19414624.0000\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21223646.0000 - val_loss: 19271530.0000\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21054674.0000 - val_loss: 19126986.0000\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20884494.0000 - val_loss: 18979320.0000\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20737538.0000 - val_loss: 18831302.0000\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20567880.0000 - val_loss: 18681946.0000\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20427950.0000 - val_loss: 18529958.0000\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20253134.0000 - val_loss: 18375126.0000\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20059018.0000 - val_loss: 18221454.0000\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19885072.0000 - val_loss: 18063766.0000\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19715086.0000 - val_loss: 17908258.0000\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19576590.0000 - val_loss: 17753358.0000\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19366322.0000 - val_loss: 17592736.0000\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19190888.0000 - val_loss: 17433488.0000\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19037860.0000 - val_loss: 17272190.0000\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18865514.0000 - val_loss: 17114778.0000\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18676850.0000 - val_loss: 16955398.0000\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18489116.0000 - val_loss: 16791318.0000\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18324924.0000 - val_loss: 16625971.0000\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18138114.0000 - val_loss: 16464398.0000\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17998276.0000 - val_loss: 16300488.0000\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17784916.0000 - val_loss: 16134254.0000\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17629160.0000 - val_loss: 15970480.0000\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17432220.0000 - val_loss: 15803256.0000\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17235254.0000 - val_loss: 15635959.0000\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17073600.0000 - val_loss: 15468412.0000\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16856662.0000 - val_loss: 15299619.0000\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16672843.0000 - val_loss: 15131817.0000\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16509805.0000 - val_loss: 14965692.0000\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16318096.0000 - val_loss: 14799391.0000\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16147616.0000 - val_loss: 14635429.0000\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15966192.0000 - val_loss: 14469020.0000\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15798880.0000 - val_loss: 14303646.0000\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15613710.0000 - val_loss: 14137425.0000\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15418033.0000 - val_loss: 13973500.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15225824.0000 - val_loss: 13807346.0000\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15050093.0000 - val_loss: 13640063.0000\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14864530.0000 - val_loss: 13476261.0000\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14727405.0000 - val_loss: 13312081.0000\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14507226.0000 - val_loss: 13148572.0000\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14344812.0000 - val_loss: 12986567.0000\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14125026.0000 - val_loss: 12822010.0000\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13961361.0000 - val_loss: 12662732.0000\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13851931.0000 - val_loss: 12501198.0000\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13662672.0000 - val_loss: 12340620.0000\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13458738.0000 - val_loss: 12180306.0000\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13257754.0000 - val_loss: 12018621.0000\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13131109.0000 - val_loss: 11859800.0000\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12926474.0000 - val_loss: 11701933.0000\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12728651.0000 - val_loss: 11545485.0000\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12554549.0000 - val_loss: 11391031.0000\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12401769.0000 - val_loss: 11234760.0000\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12201338.0000 - val_loss: 11081635.0000\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12080565.0000 - val_loss: 10927686.0000\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11875082.0000 - val_loss: 10778365.0000\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11679914.0000 - val_loss: 10627758.0000\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11557702.0000 - val_loss: 10479036.0000\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11366604.0000 - val_loss: 10331196.0000\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11252674.0000 - val_loss: 10183238.0000\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11068589.0000 - val_loss: 10038596.0000\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 10892744.0000 - val_loss: 9895234.0000\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 10803113.0000 - val_loss: 9753779.0000\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 10639497.0000 - val_loss: 9612224.0000\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9612224.0000\n",
      "Mean Squared Error on Test Data: 9612224.0\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[2038.9192  1097.5869  2062.091   1844.0277  2114.2136  2069.6023\n",
      " 1220.4161  1491.6165  2174.2302  2098.083   1287.3735  1593.0441\n",
      " 1850.2289  1725.5297  1072.2472  1242.244   1176.5437  2074.644\n",
      " 1900.2031  1104.42    1957.3247  2172.439   1582.782   1322.8228\n",
      " 1601.1848  2119.2808  1891.1886  1926.929   1186.1843  1972.4393\n",
      " 1491.1973  2400.8267  1487.4629  1749.3325  1587.2401  2068.73\n",
      " 2200.2507  2383.712   2403.2698  1308.71    1853.9442  1125.5068\n",
      " 2093.4766  2069.4548  2129.722   2634.6304  2199.1687  1431.3435\n",
      " 1989.6467  2021.8318  2403.1084  1657.8871  1222.5007  2106.5574\n",
      " 2115.3872  2263.1328  2415.4175  1857.3914  2011.2632  2451.5742\n",
      " 1611.2708  2045.9451  1865.9297  2035.5984  2246.0483  1931.8928\n",
      " 2102.934   2112.3853  1767.6326  1828.9458  1551.571   1499.0667\n",
      " 2099.1846  1670.861   1220.7397  2081.5881  1702.9717  2260.3708\n",
      "  886.25836 1971.3401  1613.7903  1233.7655  1665.455   2726.6624\n",
      " 1712.4513  1129.6072  2384.8767  1806.655   1706.3049  1736.3651\n",
      " 1338.4211  2120.8315  1832.7001  1542.5614  1391.747   1477.2003\n",
      " 1958.0024  1134.9266  2049.036   2119.7717  1965.5767  2242.0356\n",
      " 2180.8333  1282.5294  1994.5759  1818.0504  1615.0833  1971.6062\n",
      " 2283.9072  1357.1696  2121.7327  1952.6427  2084.2651  1964.9404\n",
      " 1964.5862  2131.4556  1794.3923  1105.8102  2076.1182  1536.8298\n",
      " 1467.6683  2544.3525  1568.5608  1078.8246  2042.0178  1756.0217\n",
      " 2158.6143  1831.1489  1335.7347  2261.3794  1787.0242  1899.4316\n",
      " 1727.6938  1933.3124  1894.7775  1770.259   1833.6272  1627.5386\n",
      " 1581.3413  2101.4526  1804.183   1519.2812  1320.5063  2188.4922\n",
      " 1791.5454  1737.7764  1805.0056 ]\n"
     ]
    }
   ],
   "source": [
    "day_Bike = pd.read_csv(r'C:\\Users\\jackf\\OneDrive\\Desktop\\Bike_Sharing\\UCI_Bike_Sharing\\data\\day.csv')\n",
    "features = day_Bike[['season',  'weathersit', \n",
    "                     'temp', 'atemp', 'hum', 'windspeed']]\n",
    "\n",
    "\n",
    "target = day_Bike['cnt']\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target.values, test_size=0.2, random_state=42)\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), activation='relu'))\n",
    "model.add(Dropout(0.2))  \n",
    "model.add(Dense(1))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "mse = model.evaluate(X_test, y_test)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "predictions = model.predict(X_test)\n",
    "predicted_values = np.squeeze(predictions)\n",
    "print(predicted_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c099921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1090.5117\n"
     ]
    }
   ],
   "source": [
    "new_data = pd.DataFrame({\n",
    "    'season': [1],  'weathersit': [1], 'temp': [0.215833], 'atemp': [0.223487],\n",
    "    'hum': [0.577500], 'windspeed': [0.154846]\n",
    "})\n",
    "\n",
    "\n",
    "new_features_scaled = scaler.transform(new_data)\n",
    "new_features_scaled = new_features_scaled.reshape((new_features_scaled.shape[0], 1, new_features_scaled.shape[1]))\n",
    "new_predictions = model.predict(new_features_scaled)\n",
    "predicted_cnt_values = np.squeeze(new_predictions)\n",
    "print(predicted_cnt_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb2decb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edbbd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want the value near 2729\n",
    "\n",
    "# both 2626.3992\n",
    "# without weather 2188.2783\n",
    "# just weather 1090.8662"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
